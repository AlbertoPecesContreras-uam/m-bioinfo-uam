{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "from tools.class_plots import Plots\n",
    "from tools.class_utils import Utils\n",
    "from tools.class_entropy import Entropy\n",
    "from tools.class_coherence import Coherence\n",
    "from tools.class_graph import Graph\n",
    "from tools.class_time import Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots.plot_one_group(df_tgt_pre_ctrl, channels, params = [4, 5], title = \"[TARGET] CTRL\", l = [\"CTRL\"], c = [\"b\"], size = (17, 10))\n",
    "\n",
    "# Plots.plot_two_groups(df_tgt_pre_ctrl, df_tgt_post_ctrl, best_channels, [2, 5], title = \"[TARGET] PRE-POST: CTRL\", l = [\"PRE\", \"POST\"], c = [\"g\",\"brown\"], size = (18, 7))\n",
    "\n",
    "# Plots.plot_three_groups(df_tgt_pre_ctrl, df_tgt_pre_plcb, df_tgt_pre_exp, best_channels, [2, 5], title = \"[TARGET] PRE: CTRL, PLCB, and EXP\", l = [\"CTRL\", \"PLCB\", \"EXP\"], c = [\"b\",\"black\",\"r\"], size = (18, 7))\n",
    "\n",
    "# Plots.plot_components(df_tgt_pre_ctrl, df_tgt_pre_plcb, df_tgt_pre_exp, \"Fz\", title = '[Target] - PRE: CTRL, PLCB and EXP', l = [\"CTRL\",\"PLCB\",\"EXP\"], size = (10,5))\n",
    "\n",
    "# Plots.plot_band_three_groups(df_tgt_pre_ctrl, df_tgt_pre_plcb, df_tgt_pre_exp, best_channels, band = \"delta\", params = [2,5], title = \"[Target - Delta] PRE: CTRL, PLCB and EXP\", l = [\"CTRL\", \"PLCB\", \"EXP\"], c = [\"b\",\"black\",\"r\"])\n",
    "\n",
    "# Plots.plot_band_two_groups(df_tgt_pre_ctrl, df_tgt_post_ctrl, best_channels, band = \"delta\", params = [2, 5], title = \"[Target - Delta] CTRL: PRE-POST\", l = [\"PRE\", \"POST\"], c = [\"g\",\"brown\"], size = (18, 7))\n",
    "\n",
    "# Plots.plot_groups_by_features(df_feat_tgt_post, best_channels, group = [\"CONTROL\", \"EXP\"], params = [2,5], title = \"[Target] POST: CTRL vs EXP\", l = [\"CTRL\", \"EXP\"], c = [\"b\", \"r\"], size = (18, 10), b_id = False)\n",
    "\n",
    "def get_matrix(df, grupo, comp, ch, feat):\n",
    "    return df[(df[\"grupo\"]==grupo)&(df[\"comp\"]==comp)&(df[\"ch\"]==ch)][feat]\n",
    "\n",
    "def get_id(df, grupo, comp, ch):\n",
    "    return df[(df[\"grupo\"]==grupo)&(df[\"comp\"]==comp)&(df[\"ch\"]==ch)][\"id\"]\n",
    "\n",
    "def normalize(df_feat, components):\n",
    "\n",
    "    # Lista para almacenar DataFrames normalizados por componente\n",
    "    dfs_normalizados = []\n",
    "\n",
    "    # Iterar sobre cada componente único\n",
    "    for c in components:\n",
    "        # Filtrar filas del componente actual\n",
    "        mask = df_feat['comp'] == c\n",
    "        df_componente = df_feat[mask].copy()\n",
    "        \n",
    "        # Normalizar solo las columnas de características (desde la columna 6 en adelante)\n",
    "        scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "        X_norm = scaler.fit_transform(df_componente.iloc[:, 6:])\n",
    "        \n",
    "        # Crear un nuevo DataFrame con las columnas normalizadas\n",
    "        df_norm = pd.DataFrame(\n",
    "            X_norm,\n",
    "            columns=df_componente.columns[6:],\n",
    "            index=df_componente.index  # Mantener los índices originales\n",
    "        )\n",
    "        \n",
    "        # Concatenar con las columnas no normalizadas (0 a 5)\n",
    "        df_final_componente = pd.concat([\n",
    "            df_componente.iloc[:, :6],  # Metadatos sin normalizar\n",
    "            df_norm                    # Características normalizadas\n",
    "        ], axis=1)\n",
    "        \n",
    "        dfs_normalizados.append(df_final_componente)\n",
    "\n",
    "    # Unir todos los DataFrames normalizados en uno solo\n",
    "    # Ordenar por índice original si es necesario\n",
    "    df_feat_norm = pd.concat(dfs_normalizados, axis=0).sort_index()\n",
    "\n",
    "    return df_feat_norm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grupo de psicología\n",
    "\n",
    "(-) **TAREAS ODDBALL**\n",
    "\n",
    "En el análisis bibliográfico sugieren emplear una ventana de -100ms a 750ms para capturar la respuesta al estímulo. Además, hablan de una componente bastante interesante llamada *novelty P3* (nP300), que aparece cuando el estímulo es completamente nuevo. \n",
    "\n",
    "- Sugieren estudiar esta componente.\n",
    "\n",
    "En personas de avanzada edad, el envejecimiento presenta una influencia en la amplitud y latencia de **P300**. En general, las evidencias apuntan hacia un aumento de la latencia y una disminución de la amplitud.\n",
    "\n",
    "- Sugieren que una mayor latencia es sinónimo de un peor desempeño. \n",
    "- En comparaciones de ancianos y adultos jóvenes, los ancianos muestran amplitudes mayores en regiones frontales y más bajos en regiones posteriores.\n",
    "- Estos cambios parecen reflejarse en la componente **nP300**.\n",
    "\n",
    "En varios estudios, los participantes mayores con baja actividad física mostraron valores **AUC** más altos en comparación con los demás grupos, lo que sugiere una mayor asignación de recursos neuronales en respuesta a desafíos cognitivos simples.\n",
    "\n",
    "(-) **OJOS ABIERTOS Y CERRADOS**\n",
    "\n",
    "En ancianos con edades comprendidas entre 75 y 84 años aparece un incremento en la actividad de las ondas lentas *delta* y *theta*, especialmente en las regiones temporales y occipitales izquierdas, cuando se compara con individuos entre 65 y 74 años. \n",
    "\n",
    "- En individuos mayores de 85 años, se observa un desplazamiento hacia frecuencias más bajas, con un pico espectral entre 9.0-10.0 Hz. \n",
    "- En un espectrograma se debería observar una franja en frecuencias bajas, como *delta* y *theta*.\n",
    "\n",
    "Respecto a las bandas de frecuencia en ancianos, la frecuencia pico de la banda alfa (7-14 Hz) disminuye con la edad, lo que sugiere una reducción en la actividad cerebral asociada con estados de relajación y atención. La potencia de la banda beta (15-30 Hz) también disminuye en ancianos con una mayor carga cardiometabólica, lo que puede indicar una menor actividad cognitiva y una menor capacidad de respuesta rápida.\n",
    "\n",
    "- La frecuencia pico individual de la banda *alpha* (IAF, frecuencia discreta de un individuo con la potencia más alta) se ha asociado positivamente con la resolución de interferencias en tareas de memoria y con un mejor rendimiento en tareas de atención sostenida.\n",
    "\n",
    "El grupo de psicología remarca la importancia de la **variabilidad individual**. Aunque se puedan observar patrones generales, existe una considerable variabilidad individual en todos los parámetros del EEG, lo que sugiere que los cambios en el EEG con el envejecimiento no son uniformes para todos los individuos.\n",
    "\n",
    "Existe una propiedad sobre el **comportamiento apreiódico** de la actividad cerebral, que muestra una correlación con el rendimiento cognitivo. En varios estudios, los ancianos mostraron una menor actividad aperiódica global.\n",
    "\n",
    "(-) **NEXT STEPS**\n",
    "\n",
    "- Debemos observar el comportamiento de la actividad en ondas lentas *delta* y *theta*.\n",
    "\n",
    "- Frecuencia Pico de Banda Alfa (IAF): este parámetro disminuye con la edad, indicando menor eficiencia neural. En el grupo experimental, podría esperarse que las frecuencias pico sean más altas en el instante post.\n",
    "\n",
    "- Frecuencia Pico de Banda Beta: este parámetro disminuye con la edad, indicando menor actividad cognitiva.\n",
    "\n",
    "- Deberíamos tener en cuenta una ventana de -100ms antes del estímulo *oddball*.\n",
    "- En el grupo experimental podríamos esperar una menor latencia y mayor amplitud en post, en comparación con los otros dos grupos.\n",
    "- Convendría analizar el ERP *novelty P3* (nP300).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing steps\n",
    "\n",
    "En la estimulación *oddball* se han recopilado dos mediciones EEG con el nombre *oddball Nº1* y *oddball Nº2*. Por lo tanto, cada sujeto debería poseer dos archivos (.edf) y (.mat), que guardan los timings y tipo de estímulo, respectivamente. Sin embargo, algunos de ellos solo poseen información sobre una medición. \n",
    "En cuanto al número de estímulos, sumando los *target* y *estándar*, deberían tener un total de 100, pero los rangos varían entre [80-102]. Los sujetos que tienen alguna anomalía en la duración de la medición y con el número o tipo de estímulos están controlados, anotados y separados del análisis.\n",
    "\n",
    "Para este primer apartado, hemos seleccionado todos las mediciones que poseen Nºestímulos > 90 con su respectiva información del tipo y *timing*. Así, podemos trabajar con la mayoría de las grabaciones descartando únicamente 7 por los motivos que aparecen, a continuación:\n",
    "\n",
    "- POST_Exp_33_PB_ODDBALL_1: su archivo (.edf) no posee ningún *timing* de los estímulos.\n",
    "- POST_Exp_31_PS_ODDBALL_1: su archivo (.edf) no posee ningún *timing* de los estímulos.\n",
    "- POST_Exp_47_LO_ODDBALL_1: su archivo (.edf) posee 86 estímulos marcados.\n",
    "- PRE_Exp_34_AB_ODDBALL_1: su archivo (.edf) posee 80 estímulos marcados. \n",
    "- PRE_Exp_34_AB_ODDBALL_2: su archivo (.edf) posee 80 estímulos marcados. \n",
    "- PRE_Exp_38_FL_ODDBALL_2: su archivo (.edf) posee 80 estímulos marcados. \n",
    "- PRE_Exp_65_MSR_ODDBALL_2: su archivo (.edf) posee 12 estímulos marcados.\n",
    "\n",
    "Ahora, en cada grabación EEG y por cada canal, detectamos el instante inicial de los estímulos *target* y *standard* por separado. Sabemos que existe información interesante unos instantes antes del disparo, así que hemos decidido seleccionar su comienzo 40 ms antes de lo que marca el *timing*. El tamaño de ventana seleccionado es de [-200, +700] ms cubriendo una línea base y todas las componentes de respuesta al estímulo.\n",
    "\n",
    "$$\n",
    "\\begin{array}{|c|c|}\n",
    "\\hline\n",
    "\\textbf{Ventana} & \\textbf{[ms]} \\\\\n",
    "\\hline\n",
    "\\text{$t_{o}$} & -200 \\\\ \\hline \n",
    "\\text{$t_{f}$} & +700 \\\\ \\hline\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "En cada registro EEG y por cada uno de sus 20 canales, se selecciona una ventana mediana de [-200, +700] ms para respuesta *target* y otra para respuesta *standard*. Así, tendremos 20 señales *target* y *standard* por sujeto/regristro, lo que nos permitirá extraer las componentes ERP que aparecen, a continuación: \n",
    "\n",
    "$$Event\\ Related\\ Potentials\\ (ERP)\\ Components$$\n",
    "\n",
    "$$\n",
    "\\begin{array}{|c|c|c|}\n",
    "\\hline\n",
    "\\textbf{Componentes} & \\textbf{$t_{o}$ [ms]} & \\textbf{$t_{f}$ [ms]} \\\\\n",
    "\\hline\n",
    "\\text{baseline} & -200 & -100 \\\\ \\hline\n",
    "\\text{pre-trigger} & -100 & 0 \\\\ \\hline\n",
    "\\text{post-trigger} & 0 & 80 \\\\ \\hline\n",
    "\\text{P1} & 80 & 130 \\\\ \\hline\n",
    "\\text{N1} & 130 & 200 \\\\ \\hline\n",
    "\\text{P2} & 200 & 300 \\\\ \\hline\n",
    "\\text{N2} & 300 & 360 \\\\ \\hline\n",
    "\\text{P3} & 360 & 600 \\\\ \\hline\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Data Distribution*\n",
    "\n",
    "$$\n",
    "\\begin{array}{|c|c|c|c|c|c|c|c|c|c|}\n",
    "\\hline\n",
    "\\textbf{$n_{test}$} & \\textbf{instante}  & \\textbf{grupo} & \\textbf{id} & \\textbf{type} & \\textbf{comp} & \\textbf{P8} & \\textbf{T8} & \\textbf{...} & \\textbf{P7} \\\\\n",
    "\\hline\n",
    "\\text{1} & \\text{PRE} & \\text{CONTROL} & \\text{1} & \\text{tgt} & \\text{all} & \\text{...} & \\text{...} & \\text{...} & \\text{...}\\\\\n",
    "\\hline\n",
    "\\text{1} & \\text{PRE} & \\text{CONTROL} & \\text{1} & \\text{tgt} & \\text{all} & \\text{...} & \\text{...} & \\text{...} & \\text{...}\\\\\n",
    "\\hline\n",
    "\\text{1} & \\text{PRE} & \\text{CONTROL} & \\text{1} & \\text{tgt} & \\text{all} & \\text{...} & \\text{...} & \\text{...} & \\text{...}\\\\\n",
    "\\hline\n",
    "\\text{...} & \\text{...} & \\text{...} & \\text{...} & \\text{...} & \\text{...} & \\text{...} & \\text{...} & \\text{...} & \\text{...}\\\\\n",
    "\\hline\n",
    "\\text{2} & \\text{POST} & \\text{EXP} & \\text{25} & \\text{std} & \\text{P1} & \\text{...} & \\text{...} & \\text{...} & \\text{...}\\\\\n",
    "\\hline\n",
    "\\text{2} & \\text{POST} & \\text{EXP} & \\text{25} & \\text{std} & \\text{P1} & \\text{...} & \\text{...} & \\text{...} & \\text{...}\\\\\n",
    "\\hline\n",
    "\\text{2} & \\text{POST} & \\text{EXP} & \\text{25} & \\text{std} & \\text{P1} & \\text{...} & \\text{...} & \\text{...} & \\text{...}\\\\\n",
    "\\hline\n",
    "\\text{...} & \\text{...} & \\text{...} & \\text{...} & \\text{...} & \\text{...} & \\text{...} & \\text{...} & \\text{...} & \\text{...}\\\\\n",
    "\\hline\n",
    "\\text{1} & \\text{SEG} & \\text{CONTROL} & \\text{87} & \\text{tgt} & \\text{P3} & \\text{...} & \\text{...} & \\text{...} & \\text{...}\\\\\n",
    "\\hline\n",
    "\\text{1} & \\text{SEG} & \\text{CONTROL} & \\text{87} & \\text{tgt} & \\text{P3} & \\text{...} & \\text{...} & \\text{...} & \\text{...}\\\\\n",
    "\\hline\n",
    "\\text{1} & \\text{SEG} & \\text{CONTROL} & \\text{87} & \\text{tgt} & \\text{P3} & \\text{...} & \\text{...} & \\text{...} & \\text{...}\\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize stimuli\n",
    "\n",
    "La siguiente agrupación se basa en el Sistema Internacional 10-20 para la colocación de electrodos EEG, que es el estándar en neurociencia para referenciar ubicaciones en el cuero cabelludo.\n",
    "\n",
    "Las letras indican el lóbulo donde se ubica el electrodo:\n",
    "\n",
    "$$\n",
    "\\begin{array}{|c|c|}\n",
    "\\hline\n",
    "\\textbf{Abreviatura} & \\textbf{Lóbulo} \\\\\n",
    "\\hline\n",
    "\\text{Fp} & \\text{Frontopolar} \\\\\n",
    "\\text{F} & \\text{Frontal} \\\\\n",
    "\\text{C} & \\text{Central} \\\\\n",
    "\\text{P} & \\text{Parietal} \\\\\n",
    "\\text{O} & \\text{Occipital} \\\\\n",
    "\\text{T} & \\text{Temporal} \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Los números indican si el electrodo está en el lado izquierdo (números impares), derecho (números pares) o en la línea media (letras terminadas en \"z\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths with files (.csv)\n",
    "path_tgt = \"E:/TFM/CLUSTERING_ALL_ICA_by_segments/ODDBALL/stimulus_tgt.csv\"\n",
    "path_std = \"E:/TFM/CLUSTERING_ALL_ICA_by_segments/ODDBALL/stimulus_std.csv\"\n",
    "\n",
    "# Load DataFrame for every type of stimulus\n",
    "df_w_tgt = pd.read_csv(path_tgt, header=0, delimiter=';')\n",
    "df_w_std = pd.read_csv(path_std, header=0, delimiter=';')\n",
    "\n",
    "# Common information about both DataFrames, where: df_std.columns == df_tgt.columns\n",
    "channels = df_w_std.columns[6:].to_list()\n",
    "info = df_w_std.columns[:6].to_list()\n",
    "components = df_w_std[\"comp\"].unique()\n",
    "\n",
    "# Seleccionamos instantes y grupos de TARGET DataFrames\n",
    "df_tgt_ctrl = df_w_tgt[df_w_tgt[\"grupo\"] == \"CONTROL\"]# select CTRL subjects\n",
    "df_tgt_plcb = df_w_tgt[df_w_tgt[\"grupo\"] == \"PLCB\"]# select PLCB subjects\n",
    "df_tgt_exp = df_w_tgt[df_w_tgt[\"grupo\"] == \"EXP\"]# select EXP subjects\n",
    "\n",
    "df_tgt_pre_ctrl = df_w_tgt[(df_w_tgt[\"instante\"]==\"PRE\")&(df_w_tgt[\"grupo\"]==\"CONTROL\")]\n",
    "df_tgt_pre_plcb = df_w_tgt[(df_w_tgt[\"instante\"]==\"PRE\")&(df_w_tgt[\"grupo\"]==\"PLCB\")]\n",
    "df_tgt_pre_exp = df_w_tgt[(df_w_tgt[\"instante\"]==\"PRE\")&(df_w_tgt[\"grupo\"]==\"EXP\")]\n",
    "\n",
    "df_tgt_post_ctrl = df_w_tgt[(df_w_tgt[\"instante\"]==\"POST\")&(df_w_tgt[\"grupo\"]==\"CONTROL\")]\n",
    "df_tgt_post_plcb = df_w_tgt[(df_w_tgt[\"instante\"]==\"POST\")&(df_w_tgt[\"grupo\"]==\"PLCB\")]\n",
    "df_tgt_post_exp = df_w_tgt[(df_w_tgt[\"instante\"]==\"POST\")&(df_w_tgt[\"grupo\"]==\"EXP\")]\n",
    "\n",
    "df_tgt_seg_ctrl = df_w_tgt[(df_w_tgt[\"instante\"]==\"SEGUIMIENTO\")&(df_w_tgt[\"grupo\"]==\"CONTROL\")]\n",
    "df_tgt_seg_plcb = df_w_tgt[(df_w_tgt[\"instante\"]==\"SEGUIMIENTO\")&(df_w_tgt[\"grupo\"]==\"PLCB\")]\n",
    "df_tgt_seg_exp = df_w_tgt[(df_w_tgt[\"instante\"]==\"SEGUIMIENTO\")&(df_w_tgt[\"grupo\"]==\"EXP\")]\n",
    "\n",
    "# Seleccionamos instantes y grupos de STANDARD DataFrames\n",
    "df_std_ctrl = df_w_std[df_w_std[\"grupo\"] == \"CONTROL\"]# select CTRL subjects\n",
    "df_std_plcb = df_w_std[df_w_std[\"grupo\"] == \"PLCB\"]# select PLCB subjects\n",
    "df_std_exp = df_w_std[df_w_std[\"grupo\"] == \"EXP\"]# select EXP subjects\n",
    "\n",
    "df_std_pre_ctrl = df_w_std[(df_w_std[\"instante\"]==\"PRE\")&(df_w_std[\"grupo\"]==\"CONTROL\")]\n",
    "df_std_pre_plcb = df_w_std[(df_w_std[\"instante\"]==\"PRE\")&(df_w_std[\"grupo\"]==\"PLCB\")]\n",
    "df_std_pre_exp = df_w_std[(df_w_std[\"instante\"]==\"PRE\")&(df_w_std[\"grupo\"]==\"EXP\")]\n",
    "\n",
    "df_std_post_ctrl = df_w_std[(df_w_std[\"instante\"]==\"POST\")&(df_w_std[\"grupo\"]==\"CONTROL\")]\n",
    "df_std_post_plcb = df_w_std[(df_w_std[\"instante\"]==\"POST\")&(df_w_std[\"grupo\"]==\"PLCB\")]\n",
    "df_std_post_exp = df_w_std[(df_w_std[\"instante\"]==\"POST\")&(df_w_std[\"grupo\"]==\"EXP\")]\n",
    "\n",
    "df_std_seg_ctrl = df_w_std[(df_w_std[\"instante\"]==\"SEGUIMIENTO\")&(df_w_std[\"grupo\"]==\"CONTROL\")]\n",
    "df_std_seg_plcb = df_w_std[(df_w_std[\"instante\"]==\"SEGUIMIENTO\")&(df_w_std[\"grupo\"]==\"PLCB\")]\n",
    "df_std_seg_exp = df_w_std[(df_w_std[\"instante\"]==\"SEGUIMIENTO\")&(df_w_std[\"grupo\"]==\"EXP\")]\n",
    "\n",
    "# Seleccionamos sujetos comunes entre instantes\n",
    "df_tgt_pre_ctrl,df_tgt_post_ctrl = Utils.select_common_ids(df_tgt_pre_ctrl, df_tgt_post_ctrl)\n",
    "df_tgt_pre_plcb,df_tgt_post_plcb = Utils.select_common_ids(df_tgt_pre_plcb, df_tgt_post_plcb)\n",
    "df_tgt_pre_exp,df_tgt_post_exp = Utils.select_common_ids(df_tgt_pre_exp, df_tgt_post_exp)\n",
    "\n",
    "eeg_regions = {\n",
    "    \"Frontal\": [\"Fp1\", \"Fp2\", \"F3\", \"Fz\", \"F4\", \"F7\", \"F8\"],\n",
    "    \"Central\": [\"C3\", \"Cz\", \"C4\"],\n",
    "    \"Parietal\": [\"P3\", \"Pz\", \"P4\"],\n",
    "    \"Occipital\": [\"O1\", \"Oz\", \"O2\"],\n",
    "    \"Temporal\": [\"T7\", \"T8\"],\n",
    "    \"Parieto-temporal\": [\"P7\", \"P8\"],\n",
    "    \"Parieto-occipital\": [\"P3\", \"P4\"],\n",
    "    \"Linea-media\":[\"Pz\",\"Cz\",\"Oz\"]\n",
    "}\n",
    "\n",
    "electrodes = {\n",
    "    'Fp1': (-0.4, 0.8), 'Fp2': (0.4, 0.8), \n",
    "    'F3': (-0.5, 0.4), 'F4': (0.5, 0.4),\n",
    "    'C3': (-0.6, 0), 'C4': (0.6, 0),\n",
    "    'F7': (-0.8, 0.6), 'F8': (0.8, 0.6),\n",
    "    'T7':(-1.0, 0), 'T8': (1.0, 0),\n",
    "    'Fz': (0, 0.3), 'Cz': (0, 0), 'Pz':(0, -0.3),\n",
    "    'P7': (-0.8, -0.5),'P3': (-0.5, -0.4), 'P4': (0.5, -0.4), 'P8': (0.8, -0.5),\n",
    "    'O1': (-0.4, -0.8),'Oz':(0,-0.9), 'O2': (0.4, -0.8)\n",
    "}\n",
    "\n",
    "print(\"Header with info:\",info)\n",
    "print(\"Channels:\",channels)\n",
    "print(\"Components:\",components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full-Band window\n",
    "\n",
    "**Objetivo**: \n",
    "- Visualizar los estímulos de todos los individuos de manera general, teniendo en cuenta que algunos canales son más informativos que otros.\n",
    "\n",
    "**Problema**: \n",
    "- Contamos con muchos sujetos, algunos con dos pruebas oddball. Graficarlos de forma individual no es viable, ya que requeriría demasiado tiempo.\n",
    "\n",
    "**Solución**:\n",
    "- Seleccionar y promediar las ventanas de [-200, 700] ms de todos los CONTROLES. Luego, graficar estas ventanas promediadas por canal para identificar los más informativos.\n",
    "\n",
    "**Resultado**: \n",
    "- Los canales ['P8','T8', 'P4', 'O1', 'Oz', 'O2', 'Pz', 'P3', 'T7', 'P7'] no reflejan de forma nítida la respuesta al estímulo. Vamos a separarlos para una mejor visualización. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots.plot_one_group(df_tgt_pre_ctrl, channels, params = [4, 5], title = \"[TARGET] CTRL\", l = [\"CTRL\"], c = [\"b\"], size = (17, 10))\n",
    "# Plots.plot_one_group(df_std_pre_ctrl, channels, params = [4, 5], title = \"[STANDARD] CTRL\", l = [\"CTRL\"], c = [\"b\"], size = (17, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_channels = list(set(channels) ^ set(['P8','T8', 'P4', 'O1', 'Oz', 'O2', 'Pz', 'P3', 'T7', 'P7']))  # Operador XOR (^) en conjuntos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Raw**\n",
    "\n",
    "En nuestra reunión discutimos que las diferencias observadas en términos de amplitud, tanto en instante PRE como POST, podrían ser un efecto enmascarado de posibles outliers. Por ello, se ha realizado el *plot*, que aparece en la próxima sección de código, donde reflejamos las ventanas promedio de todos los sujetos. Ahí, podemos ver que existen ciertos individuos que tuvieron algún tipo de incidencia en la grabación de la prueba, ya que presentan amplitudes abruptas sin sentido. Desgraciadamente, todos los resultados obtenidos e interpretados hasta la fecha son incorrectos porque eran fruto de artefactos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta de la carpeta\n",
    "path = './raw_data/'\n",
    "\n",
    "# Load Raw DataFrames\n",
    "raw_tgt_pre_ctrl = pd.read_csv('./raw_data/tgt_pre_ctrl.csv', header=0, delimiter=';')\n",
    "raw_tgt_post_ctrl = pd.read_csv('./raw_data/tgt_post_ctrl.csv', header=0, delimiter=';')\n",
    "\n",
    "raw_tgt_pre_plcb = pd.read_csv('./raw_data/tgt_pre_plcb.csv', header=0, delimiter=';')\n",
    "raw_tgt_post_plcb = pd.read_csv('./raw_data/tgt_post_plcb.csv', header=0, delimiter=';')\n",
    "\n",
    "raw_tgt_pre_exp = pd.read_csv('./raw_data/tgt_pre_exp.csv', header=0, delimiter=';')\n",
    "raw_tgt_post_exp = pd.read_csv('./raw_data/tgt_post_exp.csv', header=0, delimiter=';')\n",
    "\n",
    "# Plot all stimuli for CTRL\n",
    "c = [\"blue\",\"lightgray\", \"darkblue\", \"darkblue\"]\n",
    "dfs = [raw_tgt_pre_ctrl, raw_tgt_post_ctrl]\n",
    "Plots.all_stimuli(dfs, 'CTRL', c)\n",
    "\n",
    "# Plot all stimuli for PLCB\n",
    "c = [\"gray\",\"lightgray\", \"black\", \"black\"]\n",
    "dfs = [raw_tgt_pre_plcb, raw_tgt_post_plcb]\n",
    "Plots.all_stimuli(dfs, 'PLCB', c)\n",
    "\n",
    "# Plot all stimuli for EXP\n",
    "c = [\"lightcoral\",\"lightgray\", \"darkred\", \"darkred\"]\n",
    "dfs = [raw_tgt_pre_exp, raw_tgt_post_exp]\n",
    "Plots.all_stimuli(dfs, 'EXP', c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Outliers**\n",
    "\n",
    "Identifico los sujetos que presentan amplitudes bruscas sin sentido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[CTRL]\")\n",
    "print(\"ID:\",raw_tgt_post_ctrl.loc[raw_tgt_post_ctrl[\"Fz\"]>20][\"id\"].unique())\n",
    "print(\"Nº test:\",raw_tgt_post_ctrl.loc[raw_tgt_post_ctrl[\"Fz\"]>20][\"n_test\"].unique())\n",
    "print()\n",
    "print(\"[PLCB]\")\n",
    "print(\"ID:\",raw_tgt_post_plcb.loc[raw_tgt_post_plcb[\"Fz\"]>20][\"id\"].unique())\n",
    "print(\"Nº test:\",raw_tgt_post_plcb.loc[raw_tgt_post_plcb[\"Fz\"]>20][\"n_test\"].unique())\n",
    "print()\n",
    "print(\"[EXP]\")\n",
    "print(\"ID:\",raw_tgt_post_exp.loc[raw_tgt_post_exp[\"Fz\"]>20][\"id\"].unique())\n",
    "print(\"Nº test:\",raw_tgt_post_exp.loc[raw_tgt_post_exp[\"Fz\"]>20][\"n_test\"].unique())\n",
    "print(\"ID:\",raw_tgt_post_exp.loc[raw_tgt_post_exp[\"Fz\"]<-20][\"id\"].unique())\n",
    "print(\"Nº test:\",raw_tgt_post_exp.loc[raw_tgt_post_exp[\"Fz\"]<-20][\"n_test\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **ERP components**\n",
    "\n",
    "Partiendo de los datos anteriores (sin filtrar), seleccionamos el **canal Fz** por reflejar de forma nítida las diferencias tan notorias entre instantes y grupos. Al graficar **media** y **mediana**, podemos ver que definitivamente existe un sesgo por varios individuos, lo que ha resultado en unas interpretaciones erróneas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot_components(raw_tgt_pre_ctrl, raw_tgt_pre_plcb, raw_tgt_pre_exp, [\"Fz\"], title = 'Target]  PRE: CTRL, PLCB and EXP', l = [\"CTRL\",\"PLCB\",\"EXP\"], size = (18,5))\n",
    "Plots.plot_components(raw_tgt_post_ctrl, raw_tgt_post_plcb, raw_tgt_post_exp, [\"Fz\"], title = 'Target]  POST: CTRL, PLCB and EXP', l = [\"CTRL\",\"PLCB\",\"EXP\"], size = (18,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Clean**\n",
    "\n",
    "Los individuos que han mostrado esas respuestas tan extremas al estímulo han sido descartados de análisis posteriores. La extracción de las ventanas ha sufrido una ligera modificación, es decir, hemos cambiado la media por la mediana de las ventanas en cada sujeto (como explicamos en la sección \"Preprocessing steps\"). De esta forma, si cada sujeto tiene 15 estímulos **target** por cada uno de los 20 canales, se selecciona la ventana mediana en cada canal para minimizar valores extremos. Después de seleccionar la **mediana** de los estímulos, tenemos una señal más cercana a la realidad del experimento como se puede apreciar en las siguientes gráficas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all stimuli for CTRL\n",
    "c = [\"blue\",\"lightgray\", \"darkblue\", \"darkblue\"]\n",
    "dfs = [df_tgt_pre_ctrl, df_tgt_post_ctrl]\n",
    "Plots.all_stimuli(dfs, 'CTRL', c)\n",
    "\n",
    "# Plot all stimuli for PLCB\n",
    "c = [\"gray\",\"lightgray\", \"black\", \"black\"]\n",
    "dfs = [df_tgt_pre_plcb, df_tgt_post_plcb]\n",
    "Plots.all_stimuli(dfs, 'PLCB', c)\n",
    "\n",
    "# Plot all stimuli for EXP\n",
    "c = [\"lightcoral\",\"lightgray\", \"darkred\", \"darkred\"]\n",
    "dfs = [df_tgt_pre_exp, df_tgt_post_exp]\n",
    "Plots.all_stimuli(dfs, 'EXP', c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **ERP components**: Target\n",
    "\n",
    "En la sección anterior, mencionamos que cada sujeto tiene una ventana mediana por canal. Para obtener una visión general de sus respuestas, se ha graficado la ventana promedio y mediana de todos los sujetos. Esta es la razón por la que aparece una gráfica con el título de **Mean** y **Median**. \n",
    "\n",
    "En este punto, las diferencias en el instante PRE y POST no son tan notorias como en el caso anterior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot_components(df_tgt_pre_ctrl, df_tgt_pre_plcb, df_tgt_pre_exp, [\"Cz\"], title = 'Target]  PRE: CTRL, PLCB and EXP', l = [\"CTRL\",\"PLCB\",\"EXP\"], size = (18,5))\n",
    "Plots.plot_components(df_tgt_post_ctrl, df_tgt_post_plcb, df_tgt_post_exp, [\"Cz\"], title = 'Target]  POST: CTRL, PLCB and EXP', l = [\"CTRL\",\"PLCB\",\"EXP\"], size = (18,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **ERP components**: Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot_components(df_std_pre_ctrl, df_std_pre_plcb, df_std_pre_exp, [\"Fz\"], title = '[Standard] - PRE: CTRL, PLCB and EXP', l = [\"CTRL\",\"PLCB\",\"EXP\"], size = (18,5))\n",
    "Plots.plot_components(df_std_post_ctrl, df_std_post_plcb, df_std_post_exp, [\"Fz\"], title = '[Standard] - POST: CTRL, PLCB and EXP', l = [\"CTRL\",\"PLCB\",\"EXP\"], size = (18,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (-) Target\n",
    "\n",
    "En primer lugar, graficamos los grupos **CTRL**, **PLCB** y **EXP** en el instante PRE. Ponemos especial énfasis en la homogeneidad de las respuestas, ya que deberían ser similares por tratarse del instante inicial. Se puede apreciar bastante ruido generalizado a lo largo del tiempo. Las respuestas son similares, aunque el grupo **EXP** posee una actividad ligeramente superior. La idea de que parten de condiciones diferentes sigue pareciendo coherente. Sin embargo, estas diferencias no son tan apreciables como el caso de los outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Groups contrast**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot_three_groups(df_tgt_pre_ctrl, df_tgt_pre_plcb, df_tgt_pre_exp, best_channels, [2, 5], title = \"[TARGET]  PRE: CTRL, PLCB, and EXP\", l = [\"CTRL\", \"PLCB\", \"EXP\"], c = [\"b\",\"black\",\"r\"], size = (18, 7))\n",
    "Plots.plot_two_groups(df_tgt_post_ctrl, df_tgt_post_exp, best_channels, [2, 5], title = \"[TARGET]  POST: CTRL vs EXP\", l = [\"CTRL\", \"EXP\"], c = [\"b\",\"r\"], size = (18, 7))\n",
    "Plots.plot_two_groups(df_tgt_post_plcb, df_tgt_post_exp, best_channels, [2, 5], title = \"[TARGET]  POST: PLCB vs EXP\", l = [\"PLCB\", \"EXP\"], c = [\"black\",\"r\"], size = (18, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-) **PRE: CTRL-PLCB-EXP**\n",
    "\n",
    "En el instante inicial PRE, podemos observar que los grupos placebo y control presentan una respuesta al estímulo similar; en cambio, el grupo experimental muestra una actividad ligeramente superior en comparación con los demás. Dado que se trata del instante inicial, en el que todos los grupos parten de las mismas condiciones generales, esta diferencia podría deberse a las características individuales de los participantes. \n",
    "\n",
    "No obstante, ¿deberíamos darle mucha importancia?. Asumimos que los grupos son equivalentes en el instante PRE, aunque algunos sujetos presenten diferencias individuales que puedan generar variaciones en la señal.\n",
    "\n",
    "-) **POST: CTRL-EXP**\n",
    "\n",
    "En el instante POST entre **CTRL** y **EXP**, aparecen diferencias interesantes en la respuesta al estímulo. El grupo **EXP** presenta la componente N1 con una deflexión más positiva y la componente P2 posee una latencia menor.\n",
    "\n",
    "-) **POST: PLCB-EXP**\n",
    "\n",
    "En el instante POST entre **PLCB** y **EXP**, aparecen diferencias notables en la respuesta al estímulo. En el instante siguiente al disparo del estímulo, podemos observar una deflexión negativa en el grupo **PLCB** que no aparece en el grupo **EXP**. Además, las deflexiones positivas y negativas están mucho más marcadas en el grupo **PLCB**. \n",
    "\n",
    "-) **Conclusión**\n",
    "\n",
    "En términos biológicos:\n",
    "- La amplitud en **P3** refleja la cantidad de recursos neuronales que el cerebro ha destinado al procesamiento consciente del estímulo. El pico nos indica que la percepción del estímulo ha necesitado más recursos para alcanzar corteza cerebral. \n",
    "\n",
    "- La amplitud en **P2** suele estar relacionada con un procesamiento temprano de la información atencional, es decir, refleja una respuesta rápida del cerebro ante estímulos relevantes. Un aumento en P2 puede sugerir que el cerebro está destinando más recursos a la detección temprana del estímulo. \n",
    "\n",
    "- La amplitud en **N2** refleja la cantidad de recursos que el cerebro está dedicando para detectar diferencias entre estímulos.\n",
    "\n",
    "En conclusión:\n",
    "\n",
    "- Parece que el grupo  **CTRL** posee una latencia mayor en las componentes P2 y P3 en comparación con los grupos **PLCB** y **EXP**. Los instantes anteriores al dispario en el grupo **EXP** parecen presentar menor variabilidad, mientras que el grupo **CTRL** refleja algunas fluctuaciones. \n",
    "\n",
    "- El grupo **PLCB** refleja una ligera disminución de la actividad en instantes siguientes al disparo. Sus deflexiones positivas y negativas poseen un área bajo la curva considerablemente superior al grupo **CTRL** y **EXP**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instants contrast**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot_two_groups(df_tgt_pre_ctrl, df_tgt_post_ctrl, best_channels, [2, 5], title = \"[TARGET] PRE-POST: CTRL\", l = [\"PRE\", \"POST\"], c = [\"g\",\"brown\"], size = (18, 7))\n",
    "Plots.plot_two_groups(df_tgt_pre_plcb, df_tgt_post_plcb, best_channels, [2, 5], title = \"[TARGET] PRE-POST: PLCB\", l = [\"PRE\", \"POST\"], c = [\"g\",\"brown\"], size = (18, 7))\n",
    "Plots.plot_two_groups(df_tgt_pre_exp, df_tgt_post_exp, best_channels, [2, 5], title = \"[TARGET] PRE-POST: EXP\", l = [\"PRE\", \"POST\"], c = [\"g\",\"brown\"], size = (18, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-) **Controles**\n",
    "\n",
    "Al comparar ambos instantes, podemos observar que hay mucha variabilidad a lo largo de la señal. Las componentes N2 y P3 apenas son identificables. \n",
    "\n",
    "-) **Placebos**\n",
    "\n",
    "Al comparar ambos instantes, podemos observar que hay un aumento de amplitud en las componentes P1 y P2. Además, anterior al disparo existe una deflexión positiva que en el instante PRE no aparecía.\n",
    "\n",
    "-) **Experimentales**\n",
    "\n",
    "Al comparar ambos instantes dentro de los experimentales, podemos observar que existe una disminución de la actividad cerebral en las componentes N2 y P3. En el instante POST, la N2 y P3 son más diferenciables, pero con valores menos positivos.\n",
    "\n",
    "-) **Conclusión**\n",
    "\n",
    "Estas comparaciones dependen de las características individuales e iniciales de cada sujeto. Las gráficas muestran cierta variabilidad, lo que indica que no todos han mostrado el mismo comportamiento. Las conclusiones se han basado principalmente en las gráficas, pero es necesario aplicar análisis estadísticos para confirmar estos resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (-) Standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Groups contrast**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot_three_groups(df_std_pre_ctrl, df_std_pre_plcb, df_std_pre_exp, best_channels, [2, 5], title = \"[STANDARD] PRE: CTRL, PLCB, and EXP\", l = [\"CTRL\", \"PLCB\", \"EXP\"], c = [\"b\",\"black\",\"r\"], size = (18, 7))\n",
    "Plots.plot_two_groups(df_std_post_ctrl, df_std_post_exp, best_channels, [2, 5], title = \"[STANDARD] POST: CTRL vs EXP\", l = [\"CTRL\", \"EXP\"], c = [\"b\",\"r\"], size = (18, 7))\n",
    "Plots.plot_two_groups(df_std_post_plcb, df_std_post_exp, best_channels, [2, 5], title = \"[STANDARD] POST: PLCB vs EXP\", l = [\"PLCB\", \"EXP\"], c = [\"black\",\"r\"], size = (18, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-) **PRE: CTRL-PLCB-EXP**\n",
    "\n",
    "En el instante inicial PRE, podemos observar que los 3 grupos presentan una respuesta similar.\n",
    "\n",
    "-) **POST: CTRL-EXP**\n",
    "\n",
    "En el instante POST, no se observan diferencias entre los 2 grupos.\n",
    "\n",
    "-) **POST: PLCB-EXP**\n",
    "\n",
    "En el instante POST, el grupo **PLCB** posee unas deflexiones más pronunciadas en las componente N1 y P2 en comparación con el grupo **EXP**. \n",
    "\n",
    "\n",
    "-) **Conclusión**\n",
    "\n",
    "La respuesta al estímulo muestra una actividad similar entre los tres grupos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instants contrast**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot_two_groups(df_std_pre_ctrl, df_std_post_ctrl, best_channels, [2, 5], title = \"[STANDARD] PRE-POST: CTRL\", l = [\"PRE\", \"POST\"], c = [\"g\",\"brown\"], size = (18, 7))\n",
    "Plots.plot_two_groups(df_std_pre_plcb, df_std_post_plcb, best_channels, [2, 5], title = \"[STANDARD] PRE-POST: PLCB\", l = [\"PRE\", \"POST\"], c = [\"g\",\"brown\"], size = (18, 7))\n",
    "Plots.plot_two_groups(df_std_pre_exp, df_std_post_exp, best_channels, [2, 5], title = \"[STANDARD] PRE-POST: EXP\", l = [\"PRE\", \"POST\"], c = [\"g\",\"brown\"], size = (18, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-) **Controles**\n",
    "\n",
    "Al comparar ambos instantes, podemos observar que existe un desplazamiento de la componente P2. El máximo se alcanza más tarde.\n",
    "\n",
    "\n",
    "-) **Placebos**\n",
    "\n",
    "Al comparar ambos instantes, podemos observar que existe un desplazamiento de la componente P2. EL máximo se alcanza antes.\n",
    "\n",
    "-) **Experimentales**\n",
    "\n",
    "Al comparar ambos instantes dentro de los experimentales, no se aprecian diferencias relevantes.\n",
    "\n",
    "-) **Conclusión**\n",
    "\n",
    "Estamos comparando estímulos *standard* entre PRE y POST. Estos no dejan de ser tareas automáticas que los sujetos van a acabar ignorando hasta detectar los *target*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (-) Target vs Standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot_two_groups(df_std_pre_ctrl, df_tgt_pre_ctrl, best_channels, [2, 5], title = \"[PRE] CTRL: TGT vs STD\", l = [\"Standard\", \"Target\"], c = [\"b\",\"r\"], line = [\"-\",\"--\"], size = (18, 7))\n",
    "Plots.plot_two_groups(df_std_pre_plcb, df_tgt_pre_plcb, best_channels, [2, 5], title = \"[PRE] PLCB: TGT vs STD\", l = [\"Standard\", \"Target\"], c = [\"b\",\"r\"], line = [\"-\",\"--\"], size = (18, 7))\n",
    "Plots.plot_two_groups(df_std_pre_exp, df_tgt_pre_exp, best_channels, [2, 5], title = \"[PRE] EXP: TGT vs STD\", l = [\"Standard\", \"Target\"], c = [\"b\",\"r\"], line = [\"-\",\"--\"], size = (18, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- POST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot_two_groups(df_std_post_ctrl, df_tgt_post_ctrl, best_channels, [2, 5], title = \"[POST] CTRL: TGT vs STD\", l = [\"Standard\", \"Target\"], c = [\"b\",\"r\"], line = [\"-\",\"--\"], size = (18, 7))\n",
    "Plots.plot_two_groups(df_std_post_plcb, df_tgt_post_plcb, best_channels, [2, 5], title = \"[POST] PLCB: TGT vs STD\", l = [\"Standard\", \"Target\"], c = [\"b\",\"r\"], line = [\"-\",\"--\"], size = (18, 7))\n",
    "Plots.plot_two_groups(df_std_post_exp, df_tgt_post_exp, best_channels, [2, 5], title = \"[POST] EXP: TGT vs STD\", l = [\"Standard\", \"Target\"], c = [\"b\",\"r\"], line = [\"-\",\"--\"], size = (18, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cerebral-bands: $\\delta$ - $\\theta$ - $\\alpha$ - $\\beta$\n",
    "\n",
    "La descomposición de los estímulos en bandas cerebrales permite analizar las variaciones de la actividad neuronal a diferentes niveles de frecuencia, proporcionando una visión detallada de la respuesta al estímulo. Este enfoque permite identificar patrones específicos de activación neuronal entre grupos e instantes según la frecuencia analizada, facilitando la búsqueda para análisis posteriores. Para ello, hemos aplicado *PassBand Filters*, que segmentan la señal en distintos rangos, como podemos ver a continuación. \n",
    "\n",
    "$$\n",
    "\\begin{array}{|c|c|}\n",
    "\\hline\n",
    "\\textbf{Rango de Frecuencia} & \\textbf{Banda (Hz)} \\\\\n",
    "\\hline\n",
    "\\text{Delta ($\\delta$)} & 1 - 4 \\\\\n",
    "\\hline\n",
    "\\text{Theta ($\\theta$)} & 4 - 8 \\\\\n",
    "\\hline\n",
    "\\text{Alpha ($\\alpha$)} & 8 - 12 \\\\\n",
    "\\hline\n",
    "\\text{Beta ($\\beta$)} & 12 - 30 \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Delta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (-) Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Groups contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot_band_three_groups(df_tgt_pre_ctrl, df_tgt_pre_plcb, df_tgt_pre_exp, best_channels, band = \"delta\", params = [2,5], title = \"[Target - Delta] PRE: CTRL, PLCB and EXP\", l = [\"CTRL\", \"PLCB\", \"EXP\"], c = [\"b\",\"black\",\"r\"])\n",
    "Plots.plot_band_two_groups(df_tgt_post_ctrl, df_tgt_post_exp, best_channels, band = \"delta\", params = [2,5], title = \"[Target - Delta] POST: CTRL vs EXP\", l = [\"CTRL\", \"EXP\"], c = [\"b\",\"r\"], line = [\"-\",\"-\"])\n",
    "Plots.plot_band_two_groups(df_tgt_post_plcb, df_tgt_post_exp, best_channels, band = \"delta\", params = [2,5], title = \"[Target - Delta] POST: PLCB vs EXP\", l = [\"PLCB\", \"EXP\"], c = [\"black\",\"r\"], line = [\"-\",\"-\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Instants contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot_band_two_groups(df_tgt_pre_ctrl, df_tgt_post_ctrl, best_channels, band = \"delta\", params = [2, 5], title = \"[Target - Delta] CTRL: PRE-POST\", l = [\"PRE\", \"POST\"], c = [\"g\",\"brown\"], size = (18, 7))\n",
    "Plots.plot_band_two_groups(df_tgt_pre_plcb, df_tgt_post_plcb, best_channels, band = \"delta\", params = [2, 5], title = \"[Target - Delta] PLCB: PRE-POST\", l = [\"PRE\", \"POST\"], c = [\"g\",\"brown\"], size = (18, 7))\n",
    "Plots.plot_band_two_groups(df_tgt_pre_exp, df_tgt_post_exp, best_channels, band = \"delta\", params = [2, 5], title = \"[Target - Delta] EXP: PRE-POST\", l = [\"PRE\", \"POST\"], c = [\"g\",\"brown\"], size = (18, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (-) Standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Groups contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot_band_three_groups(df_std_pre_ctrl, df_std_pre_plcb, df_std_pre_exp, best_channels, band = \"delta\", params = [2,5], title = \"[Standard - Delta] PRE: CTRL, PLCB and EXP\", l = [\"CTRL\", \"PLCB\", \"EXP\"], c = [\"b\",\"black\",\"r\"], line = [\"-\",\"-\",\"-\"])\n",
    "Plots.plot_band_two_groups(df_std_post_ctrl, df_std_post_exp, best_channels, band = \"delta\", params = [2,5], title = \"[Standard - Delta] POST: CTRL vs EXP\", l = [\"CTRL\", \"EXP\"], c = [\"b\",\"r\"], line = [\"-\",\"-\"])\n",
    "Plots.plot_band_two_groups(df_std_post_plcb, df_std_post_exp, best_channels, band = \"delta\", params = [2,5], title = \"[Standard - Delta] POST: PLCB vs EXP\", l = [\"PLCB\", \"EXP\"], c = [\"black\",\"r\"], line = [\"-\",\"-\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Instants contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot_band_two_groups(df_std_pre_ctrl, df_std_post_ctrl, best_channels, band = \"delta\", params = [2, 5], title = \"[Standard - Delta] CTRL: PRE-POST\", l = [\"PRE\", \"POST\"], c = [\"g\",\"brown\"], size = (18, 7))\n",
    "Plots.plot_band_two_groups(df_std_pre_plcb, df_std_post_plcb, best_channels, band = \"delta\", params = [2, 5], title = \"[Standard - Delta] PLCB: PRE-POST\", l = [\"PRE\", \"POST\"], c = [\"g\",\"brown\"], size = (18, 7))\n",
    "Plots.plot_band_two_groups(df_std_pre_exp, df_std_post_exp, best_channels, band = \"delta\", params = [2, 5], title = \"[Standard - Delta] EXP: PRE-POST\", l = [\"PRE\", \"POST\"], c = [\"g\",\"brown\"], size = (18, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Theta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (-) Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Groups contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot_band_three_groups(df_tgt_pre_ctrl, df_tgt_pre_plcb, df_tgt_pre_exp, best_channels, band = \"theta\", params = [2,5], title = \"[Target - Theta] PRE: CTRL, PLCB and EXP\", l = [\"CTRL\", \"PLCB\", \"EXP\"], c = [\"b\",\"black\",\"r\"])\n",
    "Plots.plot_band_two_groups(df_tgt_post_ctrl, df_tgt_post_exp, best_channels, band = \"theta\", params = [2,5], title = \"[Target - Theta] POST: CTRL vs EXP\", l = [\"CTRL\", \"EXP\"], c = [\"b\",\"r\"], line = [\"-\",\"-\"])\n",
    "Plots.plot_band_two_groups(df_tgt_post_plcb, df_tgt_post_exp, best_channels, band = \"theta\", params = [2,5], title = \"[Target - Theta] POST: PLCB vs EXP\", l = [\"PLCB\", \"EXP\"], c = [\"black\",\"r\"], line = [\"-\",\"-\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Instants contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot_band_two_groups(df_tgt_pre_ctrl, df_tgt_post_ctrl, best_channels, band = \"theta\", params = [2, 5], title = \"[Target - Theta] CTRL: PRE-POST\", l = [\"PRE\", \"POST\"], c = [\"g\",\"brown\"], size = (18, 7))\n",
    "Plots.plot_band_two_groups(df_tgt_pre_plcb, df_tgt_post_plcb, best_channels, band = \"theta\", params = [2, 5], title = \"[Target - Theta] PLCB: PRE-POST\", l = [\"PRE\", \"POST\"], c = [\"g\",\"brown\"], size = (18, 7))\n",
    "Plots.plot_band_two_groups(df_tgt_pre_exp, df_tgt_post_exp, best_channels, band = \"theta\", params = [2, 5], title = \"[Target - Theta] EXP: PRE-POST\", l = [\"PRE\", \"POST\"], c = [\"g\",\"brown\"], size = (18, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (-) Standard "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Groups contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot_band_three_groups(df_std_pre_ctrl, df_std_pre_plcb, df_std_pre_exp, best_channels, band = \"theta\", params = [2,5], title = \"[Standard - Theta] PRE: CTRL, PLCB and EXP\", l = [\"CTRL\", \"PLCB\", \"EXP\"], c = [\"b\",\"black\",\"r\"])\n",
    "\n",
    "Plots.plot_band_two_groups(df_std_post_plcb, df_std_post_exp, best_channels, band = \"theta\", params = [2,5], title = \"[Standard - Theta] POST: PLCB vs EXP\", l = [\"PLCB\", \"EXP\"], c = [\"black\",\"r\"], line = [\"-\",\"-\"])\n",
    "Plots.plot_band_two_groups(df_std_post_ctrl, df_std_post_exp, best_channels, band = \"theta\", params = [2,5], title = \"[Standard - Theta] POST: CTRL vs EXP\", l = [\"CTRL\", \"EXP\"], c = [\"b\",\"r\"], line = [\"-\",\"-\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Instants contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot_band_two_groups(df_std_pre_ctrl, df_std_post_ctrl, best_channels, band = \"theta\", params = [2, 5], title = \"[Standard - Theta] CTRL: PRE-POST\", l = [\"PRE\", \"POST\"], c = [\"g\",\"brown\"], size = (18, 7))\n",
    "Plots.plot_band_two_groups(df_std_pre_plcb, df_std_post_plcb, best_channels, band = \"theta\", params = [2, 5], title = \"[Standard - Theta] PLCB: PRE-POST\", l = [\"PRE\", \"POST\"], c = [\"g\",\"brown\"], size = (18, 7))\n",
    "Plots.plot_band_two_groups(df_std_pre_exp, df_std_post_exp, best_channels, band = \"theta\", params = [2, 5], title = \"[Standard] - Theta] EXP: PRE-POST\", l = [\"PRE\", \"POST\"], c = [\"g\",\"brown\"], size = (18, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Alpha**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (-) Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Groups contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot_band_three_groups(df_tgt_pre_ctrl, df_tgt_pre_plcb, df_tgt_pre_exp, best_channels, band = \"alpha\", params = [2,5], title = \"[Target - Alpha] PRE: CTRL, PLCB and EXP\", l = [\"CTRL\", \"PLCB\", \"EXP\"], c = [\"b\",\"black\",\"r\"])\n",
    "Plots.plot_band_two_groups(df_tgt_post_ctrl, df_tgt_post_exp, best_channels, band = \"alpha\", params = [2,5], title = \"[Target - Alpha] POST: CTRL vs EXP\", l = [\"CTRL\", \"EXP\"], c = [\"b\",\"r\"], line = [\"-\",\"-\"])\n",
    "Plots.plot_band_two_groups(df_tgt_post_plcb, df_tgt_post_exp, best_channels, band = \"alpha\", params = [2,5], title = \"[Target - Alpha] POST: PLCB vs EXP\", l = [\"PLCB\", \"EXP\"], c = [\"black\",\"r\"], line = [\"-\",\"-\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Instants contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot_band_two_groups(df_tgt_pre_ctrl, df_tgt_post_ctrl, best_channels, band = \"alpha\", params = [2, 5], title = \"[Target - Alpha] CTRL: PRE-POST\", l = [\"PRE\", \"POST\"], c = [\"g\",\"brown\"], size = (18, 7))\n",
    "Plots.plot_band_two_groups(df_tgt_pre_plcb, df_tgt_post_plcb, best_channels, band = \"alpha\", params = [2, 5], title = \"[Target - Alpha] PLCB: PRE-POST\", l = [\"PRE\", \"POST\"], c = [\"g\",\"brown\"], size = (18, 7))\n",
    "Plots.plot_band_two_groups(df_tgt_pre_exp, df_tgt_post_exp, best_channels, band = \"alpha\", params = [2, 5], title = \"[Target - Alpha] EXP: PRE-POST\", l = [\"PRE\", \"POST\"], c = [\"g\",\"brown\"], size = (18, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (-) Standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Groups contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot_band_three_groups(df_std_pre_ctrl, df_std_pre_plcb, df_std_pre_exp, best_channels, band = \"alpha\", params = [2,5], title = \"[Standard - Alpha] PRE: CTRL, PLCB and EXP\", l = [\"CTRL\", \"PLCB\", \"EXP\"], c = [\"b\",\"black\",\"r\"])\n",
    "Plots.plot_band_two_groups(df_std_post_plcb, df_std_post_exp, best_channels, band = \"alpha\", params = [2,5], title = \"[Standard - Alpha] POST: PLCB vs EXP\", l = [\"PLCB\", \"EXP\"], c = [\"black\",\"r\"], line = [\"-\",\"-\"])\n",
    "Plots.plot_band_two_groups(df_std_post_ctrl, df_std_post_exp, best_channels, band = \"alpha\", params = [2,5], title = \"[Standard - Alpha] POST: CTRL vs EXP\", l = [\"CTRL\", \"EXP\"], c = [\"b\",\"r\"], line = [\"-\",\"-\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Instants contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot_band_two_groups(df_std_pre_ctrl, df_std_post_ctrl, best_channels, band = \"alpha\", params = [2, 5], title = \"[Standard - Alpha] CTRL: PRE-POST\", l = [\"PRE\", \"POST\"], c = [\"g\",\"brown\"], size = (18, 7))\n",
    "Plots.plot_band_two_groups(df_std_pre_plcb, df_std_post_plcb, best_channels, band = \"alpha\", params = [2, 5], title = \"[Standard - Alpha] PLCB: PRE-POST\", l = [\"PRE\", \"POST\"], c = [\"g\",\"brown\"], size = (18, 7))\n",
    "Plots.plot_band_two_groups(df_std_pre_exp, df_std_post_exp, best_channels, band = \"alpha\", params = [2, 5], title = \"[Standard] - Alpha] EXP: PRE-POST\", l = [\"PRE\", \"POST\"], c = [\"g\",\"brown\"], size = (18, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Beta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (-) Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Groups contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot_band_three_groups(df_tgt_pre_ctrl, df_tgt_pre_plcb, df_tgt_pre_exp, best_channels, band = \"beta\", params = [2,5], title = \"[Target - Beta] PRE: CTRL, PLCB and EXP\", l = [\"CTRL\", \"PLCB\", \"EXP\"], c = [\"b\",\"black\",\"r\"])\n",
    "Plots.plot_band_two_groups(df_tgt_post_ctrl, df_tgt_post_exp, best_channels, band = \"beta\", params = [2,5], title = \"[Target - Beta] POST: CTRL vs EXP\", l = [\"CTRL\", \"EXP\"], c = [\"b\",\"r\"], line = [\"-\",\"-\"])\n",
    "Plots.plot_band_two_groups(df_tgt_post_plcb, df_tgt_post_exp, best_channels, band = \"beta\", params = [2,5], title = \"[Target - Beta] POST: PLCB vs EXP\", l = [\"PLCB\", \"EXP\"], c = [\"black\",\"r\"], line = [\"-\",\"-\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Instants contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot_band_two_groups(df_tgt_pre_ctrl, df_tgt_post_ctrl, best_channels, band = \"beta\", params = [2, 5], title = \"[Target - Beta] CTRL: PRE-POST\", l = [\"PRE\", \"POST\"], c = [\"g\",\"brown\"], size = (18, 7))\n",
    "Plots.plot_band_two_groups(df_tgt_pre_plcb, df_tgt_post_plcb, best_channels, band = \"beta\", params = [2, 5], title = \"[Target - Beta] PLCB: PRE-POST\", l = [\"PRE\", \"POST\"], c = [\"g\",\"brown\"], size = (18, 7))\n",
    "Plots.plot_band_two_groups(df_tgt_pre_exp, df_tgt_post_exp, best_channels, band = \"beta\", params = [2, 5], title = \"[Target - Beta] EXP: PRE-POST\", l = [\"PRE\", \"POST\"], c = [\"g\",\"brown\"], size = (18, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (-) Standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Groups contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot_band_three_groups(df_std_pre_ctrl, df_std_pre_plcb, df_std_pre_exp, best_channels, band = \"beta\", params = [2,5], title = \"[Standard - Beta] PRE: CTRL, PLCB and EXP\", l = [\"CTRL\", \"PLCB\", \"EXP\"], c = [\"b\",\"black\",\"r\"])\n",
    "\n",
    "Plots.plot_band_two_groups(df_std_post_plcb, df_std_post_exp, best_channels, band = \"beta\", params = [2,5], title = \"[Standard - Beta] POST: PLCB vs EXP\", l = [\"PLCB\", \"EXP\"], c = [\"black\",\"r\"], line = [\"-\",\"-\"])\n",
    "Plots.plot_band_two_groups(df_std_post_ctrl, df_std_post_exp, best_channels, band = \"beta\", params = [2,5], title = \"[Standard - Beta] POST: CTRL vs EXP\", l = [\"CTRL\", \"EXP\"], c = [\"b\",\"r\"], line = [\"-\",\"-\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Instants contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot_band_two_groups(df_std_pre_ctrl, df_std_post_ctrl, best_channels, band = \"beta\", params = [2, 5], title = \"[Standard - Beta] CTRL: PRE-POST\", l = [\"PRE\", \"POST\"], c = [\"g\",\"brown\"], size = (18, 7))\n",
    "Plots.plot_band_two_groups(df_std_pre_plcb, df_std_post_plcb, best_channels, band = \"beta\", params = [2, 5], title = \"[Standard - Beta] PLCB: PRE-POST\", l = [\"PRE\", \"POST\"], c = [\"g\",\"brown\"], size = (18, 7))\n",
    "Plots.plot_band_two_groups(df_std_pre_exp, df_std_post_exp, best_channels, band = \"beta\", params = [2, 5], title = \"[Standard] - Beta] EXP: PRE-POST\", l = [\"PRE\", \"POST\"], c = [\"g\",\"brown\"], size = (18, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    "\n",
    "En esta sección, realizaremos un análisis estadístico con la **media** y **varianza** de las señales. Sin embargo, es importante tener en cuenta que las **características** han sido **extraídas de la ventana mediana** de cada uno de los 20 canales que posee cada sujeto. Más adelante, repetiremos el análisis promediando las características de cada ventana para garantizar una mayor consistencia.\n",
    "\n",
    "**Objetivo**: \n",
    "- Analizar las ventanas en el rango de [-200, 700] ms a través de la media y la varianza por cada canal. \n",
    "- Cada punto en las gráficas representa un sujeto en un canal específico.\n",
    "- Al graficar estas características, buscamos identificar posibles patrones o diferencias entre grupos o instantes.\n",
    "\n",
    "**Consideraciones**: \n",
    "- Si bien los análisis previos sugieren que las **diferencias más relevantes** pueden encontrarse en **componentes específicas**, esta visualización nos dará una primera aproximación. Luego, aplicaremos análisis estadísticos para contrastar las diferencias que hemos detectado de forma visual. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize channels\n",
    "\n",
    "Al graficar la distribución de los sujetos en estímulos *target* y *standard*, hay dificultades para analizar correctamente la disposición espacial de los puntos. Hemos decidido apartar los sujetos con valores extremos y, así, tener una imagen limpia que refleje patrones o diferencias entre grupos, instantes o canales. \n",
    "\n",
    "Consideraciones:\n",
    "- Estos sujetos solo son removidos para una visualización más clara. En los análisis posteriores se emplean todos los datos disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_tgt = \"E:/TFM/CLUSTERING_ALL_ICA_by_segments/ODDBALL/features_tgt.csv\"\n",
    "path_std = \"E:/TFM/CLUSTERING_ALL_ICA_by_segments/ODDBALL/features_std.csv\"\n",
    "\n",
    "df_feat_tgt = pd.read_csv(path_tgt, header=0, delimiter=';')\n",
    "df_feat_std = pd.read_csv(path_std, header=0, delimiter=';')\n",
    "\n",
    "channels = df_feat_tgt[\"ch\"].unique()\n",
    "\n",
    "grupos = [\"CONTROL\",\"PLCB\",\"EXP\"]\n",
    "best_channels = list(set(channels) ^ set(['P8','T8', 'P4', 'O1', 'Oz', 'O2', 'Pz', 'P3', 'T7', 'P7']))  # Operador XOR (^) en conjuntos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (-) Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removemos sujetos con valores extremos\n",
    "df_feat_tgt = Utils.remove_subjects(df_feat_tgt, [10,11,12,29,44,45,60,73,76])\n",
    "\n",
    "# Normalizamos agrupando por componentes, ya que son datos diferentes\n",
    "df_feat_tgt_norm = normalize(df_feat_tgt, components)\n",
    "\n",
    "# Seleccionamos instantes PRE y POST para caracteristicas de estimulos Target\n",
    "df_feat_tgt_pre, df_feat_tgt_post = Utils.group_by(df_feat_tgt_norm, col=\"instante\", val=[\"PRE\",\"POST\"])\n",
    "\n",
    "# Seleccionamos grupos CTRL, PLCB y EXP para caracteristicas de estimulos Target\n",
    "df_feat_tgt_ctrl, df_feat_tgt_plcb, df_feat_tgt_exp = Utils.group_by(df_feat_tgt_norm, col=\"grupo\", val=grupos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "comp = \"all\"\n",
    "\n",
    "# Configurar figura y ejes (4x4)\n",
    "fig, axes = plt.subplots(2, 4, figsize=(18, 10))\n",
    "fig.suptitle(\"Comparación PRE vs POST por Región EEG (Mean)\", fontsize=16, y=1.02)\n",
    "\n",
    "# Aplanar ejes para iterar fácilmente\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Iterar sobre cada región EEG\n",
    "for i, (region_name, channels) in enumerate(eeg_regions.items()):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Filtrar datos PRE y POST para la región actual\n",
    "    region_pre = df_feat_tgt_pre[(df_feat_tgt_pre[\"ch\"].isin(channels)) & (df_feat_tgt_pre[\"comp\"] == comp)]\n",
    "    region_post = df_feat_tgt_post[(df_feat_tgt_post[\"ch\"].isin(channels)) & (df_feat_tgt_post[\"comp\"] == comp)]\n",
    "    \n",
    "    # Asegurar que los IDs coincidan\n",
    "    region_pre, region_post = Utils.select_common_ids(region_pre, region_post)\n",
    "    \n",
    "    # Calcular promedios por grupo\n",
    "    avg_pre, avg_post = Utils.average_by_feature(data = [region_pre, region_post], features = [\"mean\"])\n",
    "    ctrl_pre, plcb_pre, exp_pre = Utils.group_by(avg_pre, col=\"grupo\", val=[\"CONTROL\", \"PLCB\", \"EXP\"])\n",
    "    ctrl_post, plcb_post, exp_post = Utils.group_by(avg_post, col=\"grupo\", val=[\"CONTROL\", \"PLCB\", \"EXP\"])\n",
    "    \n",
    "    # Scatter plot por grupo\n",
    "    ax.scatter(ctrl_pre[\"mean\"], ctrl_post[\"mean\"], color='blue', label=\"CONTROL\", alpha=0.7)\n",
    "    ax.scatter(plcb_pre[\"mean\"], plcb_post[\"mean\"], color='gray', label=\"PLCB\", alpha=0.7)\n",
    "    ax.scatter(exp_pre[\"mean\"], exp_post[\"mean\"], color='red', label=\"EXP\", alpha=0.7)\n",
    "    \n",
    "    # Ajustes del subplot\n",
    "    ax.set_title(region_name, fontsize=12)\n",
    "    ax.set_xlabel(\"PRE (mean)\", fontsize=10)\n",
    "    ax.set_ylabel(\"POST (mean)\", fontsize=10)\n",
    "    ax.grid(linestyle='--', alpha=0.3)\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "# Ocultar ejes vacíos si hay menos de 16 regiones\n",
    "for j in range(i + 1, len(axes)):\n",
    "    axes[j].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "comp = \"all\"\n",
    "\n",
    "# Configurar figura y ejes (4x4)\n",
    "fig, axes = plt.subplots(2, 4, figsize=(18, 10))\n",
    "fig.suptitle(\"Comparación PRE vs POST por Región EEG (Std)\", fontsize=16, y=1.02)\n",
    "\n",
    "# Aplanar ejes para iterar fácilmente\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Iterar sobre cada región EEG\n",
    "for i, (region_name, channels) in enumerate(eeg_regions.items()):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Filtrar datos PRE y POST para la región actual\n",
    "    region_pre = df_feat_tgt_pre[(df_feat_tgt_pre[\"ch\"].isin(channels)) & (df_feat_tgt_pre[\"comp\"] == comp)]\n",
    "    region_post = df_feat_tgt_post[(df_feat_tgt_post[\"ch\"].isin(channels)) & (df_feat_tgt_post[\"comp\"] == comp)]\n",
    "    \n",
    "    # Asegurar que los IDs coincidan\n",
    "    region_pre, region_post = Utils.select_common_ids(region_pre, region_post)\n",
    "    \n",
    "    # Calcular promedios por grupo\n",
    "    avg_pre, avg_post = Utils.average_by_feature(data = [region_pre, region_post], features = [\"std\"])\n",
    "    ctrl_pre, plcb_pre, exp_pre = Utils.group_by(avg_pre, col=\"grupo\", val=[\"CONTROL\", \"PLCB\", \"EXP\"])\n",
    "    ctrl_post, plcb_post, exp_post = Utils.group_by(avg_post, col=\"grupo\", val=[\"CONTROL\", \"PLCB\", \"EXP\"])\n",
    "    \n",
    "    # Scatter plot por grupo\n",
    "    ax.scatter(ctrl_pre[\"std\"], ctrl_post[\"std\"], color='blue', label=\"CONTROL\", alpha=0.7)\n",
    "    ax.scatter(plcb_pre[\"std\"], plcb_post[\"std\"], color='gray', label=\"PLCB\", alpha=0.7)\n",
    "    ax.scatter(exp_pre[\"std\"], exp_post[\"std\"], color='red', label=\"EXP\", alpha=0.7)\n",
    "    \n",
    "    # Ajustes del subplot\n",
    "    ax.set_title(region_name, fontsize=12)\n",
    "    ax.set_xlabel(\"PRE (std)\", fontsize=10)\n",
    "    ax.set_ylabel(\"POST (std)\", fontsize=10)\n",
    "    ax.grid(linestyle='--', alpha=0.3)\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "# Ocultar ejes vacíos si hay menos de 16 regiones\n",
    "for j in range(i + 1, len(axes)):\n",
    "    axes[j].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Groups contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot_groups_by_features(df_feat_tgt_post, best_channels, group = [\"CONTROL\", \"EXP\"], params = [2,5], title = \"[Target] POST: CTRL vs EXP\", l = [\"CTRL\", \"EXP\"], c = [\"b\", \"r\"], size = (18, 10), b_id = False)\n",
    "Plots.plot_groups_by_features(df_feat_tgt_post, best_channels, group = [\"PLCB\", \"EXP\"], params = [2,5], title = \"[Target] POST: PLCB vs EXP\", l = [\"PLCB\", \"EXP\"], c = [\"black\", \"r\"], size = (18, 10), b_id = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Instants contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot_instants_by_features(df_feat_tgt_ctrl, best_channels, instant = [\"PRE\", \"POST\"], params = [2,5], title = \"[Target] CTRL: PRE vs POST\", l = [\"PRE\", \"POST\"], c = [\"green\", \"brown\"], size = (18, 10))\n",
    "Plots.plot_instants_by_features(df_feat_tgt_plcb, best_channels, instant = [\"PRE\", \"POST\"], params = [2,5], title = \"[Target] PLCB: PRE vs POST\", l = [\"PRE\", \"POST\"], c = [\"green\", \"brown\"], size = (18, 10))\n",
    "Plots.plot_instants_by_features(df_feat_tgt_exp, best_channels, instant = [\"PRE\", \"POST\"], params = [2,5], title = \"[Target] EXP: PRE vs POST\", l = [\"PRE\", \"POST\"], c = [\"green\", \"brown\"], size = (18, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (-) Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removemos sujetos con valores extremos\n",
    "df_feat_std = Utils.remove_subjects(df_feat_std, [26,29,38,78])\n",
    "\n",
    "# Normalizamos agrupando por componentes, ya que son datos diferentes\n",
    "df_feat_std_norm = normalize(df_feat_std, components)\n",
    "\n",
    "# Seleccionamos instantes PRE y POST para caracteristicas de estimulos Standard\n",
    "df_feat_std_pre, df_feat_std_post = Utils.group_by(df_feat_std_norm, col=\"instante\", val=[\"PRE\",\"POST\"])\n",
    "\n",
    "# Seleccionamos grupos CTRL, PLCB y EXP para caracteristicas de estimulos Standard\n",
    "df_feat_std_ctrl, df_feat_std_plcb, df_feat_std_exp = Utils.group_by(df_feat_std_norm, col=\"grupo\", val=[\"CONTROL\", \"PLCB\", \"EXP\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Groups contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot_groups_by_features(df_feat_std_pre, best_channels, group = [\"CONTROL\", \"PLCB\", \"EXP\"], params = [4,5], title = \"[Standard] PRE: CTRL, PLCB and EXP\", l = [\"CTRL\", \"PLCB\", \"EXP\"], c = [\"b\", \"black\", \"r\"], size = (18, 15), b_id = False)\n",
    "Plots.plot_groups_by_features(df_feat_std_post, best_channels, group = [\"CONTROL\", \"PLCB\", \"EXP\"], params = [4,5], title = \"[Standard] POST: CTRL, PLCB and EXP\", l = [\"CTRL\", \"PLCB\", \"EXP\"], c = [\"b\", \"black\", \"r\"], size = (18, 15), b_id = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Instants contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot_instants_by_features(df_feat_std_ctrl, best_channels, instant = [\"PRE\", \"POST\"], params = [2,5], title = \"[Standard] CTRL: PRE vs POST\", l = [\"PRE\", \"POST\"], c = [\"green\", \"brown\"], size = (18, 10))\n",
    "Plots.plot_instants_by_features(df_feat_std_plcb, best_channels, instant = [\"PRE\", \"POST\"], params = [2,5], title = \"[Standard] PLCB: PRE vs POST\", l = [\"PRE\", \"POST\"], c = [\"green\", \"brown\"], size = (18, 10))\n",
    "Plots.plot_instants_by_features(df_feat_std_exp, best_channels, instant = [\"PRE\", \"POST\"], params = [2,5], title = \"[Standard] EXP: PRE vs POST\", l = [\"PRE\", \"POST\"], c = [\"green\", \"brown\"], size = (18, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical analysis\n",
    "\n",
    "A partir de las características **media** y **varianza**, vamos a comparar si existen diferencias significativas entre instantes dentro de cada grupo. Lo ideal sería obtener resultados consistentes con las gráficas que obtuvimos en las primeras secciones. Nuestra hipótesis sugiere que las diferencias se deberían presentar principalmente en las componentes ERP. \n",
    "\n",
    "- Estos resultados nos permitirán profundizar en el entendimiento del comportamiento de los sujetos bajo diferentes intervenciones. \n",
    "- Como primera aproximación, demostraríamos que existen patrones discriminantes entre instantes dentro de cada grupo.\n",
    "\n",
    "Los contrastes se realizan de la siguiente manera:\n",
    "\n",
    "- Dentro de un mismo grupo, seleccionamos la componente P3, por ejemplo, y comparamos todos los sujetos en el instante PRE frente al POST. \n",
    "- Para la comparación, tomamos en cuenta todos los canales del sujeto, es decir, construimos distribuciones para PRE y POST que incluyen toda la variabilidad.\n",
    "- Aplicamos una prueba estadística no paramétrica de Wilcoxon y una corrección por el método de False Discovery Rate (Benjamini-Hochberg)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta para archivos con características de estímulos Target (tgt) y Standard (std)\n",
    "path_tgt = \"E:/TFM/CLUSTERING_ALL_ICA_by_segments/ODDBALL/features_tgt.csv\"\n",
    "path_std = \"E:/TFM/CLUSTERING_ALL_ICA_by_segments/ODDBALL/features_std.csv\"\n",
    "\n",
    "# Cargamos ambos archivos en forma de DataFrames\n",
    "df_feat_tgt = pd.read_csv(path_tgt, header=0, delimiter=';')\n",
    "df_feat_std = pd.read_csv(path_std, header=0, delimiter=';')\n",
    "\n",
    "# Informacion sobre los DataFrames\n",
    "info = df_feat_tgt.columns[:6].to_list()\n",
    "channels = df_feat_tgt[\"ch\"].unique().tolist()\n",
    "components = df_feat_tgt[\"comp\"].unique().tolist()\n",
    "grupos = [\"CONTROL\", \"PLCB\", \"EXP\"]\n",
    "features = [\"mean\",\"std\"]\n",
    "\n",
    "eeg_regions = {\n",
    "    \"Frontal\": [\"Fp1\", \"Fp2\", \"F3\", \"Fz\", \"F4\", \"F7\", \"F8\"],\n",
    "    \"Central\": [\"C3\", \"Cz\", \"C4\"],\n",
    "    \"Parietal\": [\"P3\", \"Pz\", \"P4\"],\n",
    "    \"Occipital\": [\"O1\", \"Oz\", \"O2\"],\n",
    "    \"Temporal\": [\"T7\", \"T8\"],\n",
    "    \"Parieto-temporal\": [\"P7\", \"P8\"],\n",
    "    \"Parieto-occipital\": [\"P3\", \"P4\"],\n",
    "    \"Linea-media\":[\"Pz\",\"Cz\",\"Oz\"],\n",
    "    \"All\":channels\n",
    "}\n",
    "\n",
    "# Display info\n",
    "print(\"Header with info:\",info)\n",
    "print(\"Channels:\",channels)\n",
    "print(\"Components:\",components)\n",
    "print(\"Features:\", features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_paired_test(pre, post, feat, channels, flag=\"wilcoxon\"):\n",
    "    \n",
    "    import scipy.stats as stats\n",
    "    \n",
    "    combined_dict = {key: [pre[key], post[key]] for key in pre}\n",
    "\n",
    "    comparaciones = []\n",
    "    for grupo, (pre, post) in combined_dict.items():\n",
    "        p_values = []  \n",
    "        for ch in channels:\n",
    "        #for region, ch_group in eeg_regions.items():\n",
    "\n",
    "            # Seleccionamos los electrodos que conforman cada region cerebral\n",
    "            post_data = post[post['ch'].isin([ch])]\n",
    "            pre_data = pre[pre['ch'].isin([ch])]\n",
    "\n",
    "            # Promediamos los canales por caracteristicas\n",
    "            #avg_pre, avg_post = Utils.average_by_feature([pre_data, post_data], [feat])\n",
    "            \n",
    "            if pre_data[feat].mean() < post_data[feat].mean():\n",
    "                contrast = \"PRE < POST\"\n",
    "            else:\n",
    "                contrast = \"PRE > POST\"\n",
    "\n",
    "            if flag==\"wilcoxon\":\n",
    "                t_stat, p_value = stats.wilcoxon(pre_data[feat], post_data[feat])\n",
    "\n",
    "            else:\n",
    "                t_stat, p_value = stats.ttest_rel(pre_data[feat], post_data[feat])\n",
    "\n",
    "            p_values.append(p_value)\n",
    "\n",
    "            comparaciones.append({\n",
    "                \"feat\":feat,\n",
    "                \"grupo\": grupo,\n",
    "                \"comp\": pre[\"comp\"].unique()[0],\n",
    "                \"region\": ch,\n",
    "                \"contrast\": contrast,\n",
    "                \"t_stat\": t_stat,\n",
    "                \"p_value\": p_value\n",
    "            })\n",
    "        \n",
    "\n",
    "    return pd.DataFrame(comparaciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (-) Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizamos agrupando por componentes, ya que son datos diferentes\n",
    "df_feat_tgt_norm = normalize(df_feat_tgt, components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-) **Mean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "feat = \"mean\"\n",
    "\n",
    "for df_comp in Utils.group_by(df_feat_tgt_norm, col=\"comp\", val=components):\n",
    "\n",
    "    tgt_feat_pre, tgt_feat_post = Utils.group_by(df_comp, col=\"instante\", val=[\"PRE\",\"POST\"])\n",
    "    tgt_feat_pre, tgt_feat_post = Utils.select_common_ids(tgt_feat_pre, tgt_feat_post)\n",
    "\n",
    "    feat_pre_ctrl, feat_pre_plcb, feat_pre_exp = Utils.group_by(tgt_feat_pre, col=\"grupo\", val=grupos)\n",
    "    feat_post_ctrl, feat_post_plcb, feat_post_exp = Utils.group_by(tgt_feat_post, col=\"grupo\", val=grupos)\n",
    "\n",
    "    pre = dict(zip(grupos, Utils.group_by(tgt_feat_pre, col=\"grupo\", val=grupos)))\n",
    "    post = dict(zip(grupos, Utils.group_by(tgt_feat_post, col=\"grupo\", val=grupos)))\n",
    "\n",
    "    df = compute_paired_test(pre, post, feat, channels, flag=\"wilcoxon\")\n",
    "\n",
    "    results.append(df)\n",
    "\n",
    "df_tests = pd.concat(results).reset_index(drop=True)\n",
    "\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "adj_results = []\n",
    "\n",
    "for df in Utils.group_by(df_tests, col=\"grupo\", val=grupos):\n",
    "\n",
    "    for df_comp in Utils.group_by(df, col=\"comp\", val=components):\n",
    "\n",
    "        _,adj_p_val,_,_ = multipletests(df_comp[\"p_value\"], method=\"fdr_bh\")\n",
    "\n",
    "        df_comp[\"adj_p_value\"] = adj_p_val\n",
    "\n",
    "        adj_results.append(df_comp)\n",
    "\n",
    "df_adj_tests = pd.concat(adj_results).reset_index(drop=True)\n",
    "\n",
    "# df_adj_tests[df_adj_tests[\"adj_p_value\"]<0.05]\n",
    "df_tests[df_tests[\"p_value\"]<0.05]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-) **Standard Deviation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "feat = \"std\"\n",
    "\n",
    "for df_comp in Utils.group_by(df_feat_tgt_norm, col=\"comp\", val=components):\n",
    "\n",
    "    tgt_feat_pre, tgt_feat_post = Utils.group_by(df_comp, col=\"instante\", val=[\"PRE\",\"POST\"])\n",
    "    tgt_feat_pre, tgt_feat_post = Utils.select_common_ids(tgt_feat_pre, tgt_feat_post)\n",
    "\n",
    "    feat_pre_ctrl, feat_pre_plcb, feat_pre_exp = Utils.group_by(tgt_feat_pre, col=\"grupo\", val=grupos)\n",
    "    feat_post_ctrl, feat_post_plcb, feat_post_exp = Utils.group_by(tgt_feat_post, col=\"grupo\", val=grupos)\n",
    "\n",
    "    pre = dict(zip(grupos, Utils.group_by(tgt_feat_pre, col=\"grupo\", val=grupos)))\n",
    "    post = dict(zip(grupos, Utils.group_by(tgt_feat_post, col=\"grupo\", val=grupos)))\n",
    "\n",
    "    df = compute_paired_test(pre, post, feat, channels, flag=\"wilcoxon\")\n",
    "\n",
    "    results.append(df)\n",
    "\n",
    "df_tests = pd.concat(results).reset_index(drop=True)\n",
    "\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "adj_results = []\n",
    "\n",
    "for df in Utils.group_by(df_tests, col=\"grupo\", val=grupos):\n",
    "\n",
    "    for df_comp in Utils.group_by(df, col=\"comp\", val=components):\n",
    "\n",
    "        _,adj_p_val,_,_ = multipletests(df_comp[\"p_value\"], method=\"fdr_bh\")\n",
    "\n",
    "        df_comp[\"adj_p_value\"] = adj_p_val\n",
    "\n",
    "        adj_results.append(df_comp)\n",
    "\n",
    "df_adj_tests = pd.concat(adj_results).reset_index(drop=True)\n",
    "\n",
    "df_adj_tests[df_adj_tests[\"adj_p_value\"]<0.05]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (-) Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizamos agrupando por componentes, ya que son datos diferentes\n",
    "df_feat_std_norm = normalize(df_feat_std, components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-) **Mean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "feat = \"mean\"\n",
    "\n",
    "for df_comp in Utils.group_by(df_feat_std_norm, col=\"comp\", val=components):\n",
    "\n",
    "    tgt_feat_pre, tgt_feat_post = Utils.group_by(df_comp, col=\"instante\", val=[\"PRE\",\"POST\"])\n",
    "    tgt_feat_pre, tgt_feat_post = Utils.select_common_ids(tgt_feat_pre, tgt_feat_post)\n",
    "\n",
    "    feat_pre_ctrl, feat_pre_plcb, feat_pre_exp = Utils.group_by(tgt_feat_pre, col=\"grupo\", val=grupos)\n",
    "    feat_post_ctrl, feat_post_plcb, feat_post_exp = Utils.group_by(tgt_feat_post, col=\"grupo\", val=grupos)\n",
    "\n",
    "    pre = dict(zip(grupos, Utils.group_by(tgt_feat_pre, col=\"grupo\", val=grupos)))\n",
    "    post = dict(zip(grupos, Utils.group_by(tgt_feat_post, col=\"grupo\", val=grupos)))\n",
    "\n",
    "    df = compute_paired_test(pre, post, feat, channels, flag=\"wilcoxon\")\n",
    "\n",
    "    results.append(df)\n",
    "\n",
    "df_tests = pd.concat(results).reset_index(drop=True)\n",
    "\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "adj_results = []\n",
    "\n",
    "for df in Utils.group_by(df_tests, col=\"grupo\", val=grupos):\n",
    "\n",
    "    for df_comp in Utils.group_by(df, col=\"comp\", val=components):\n",
    "\n",
    "        _,adj_p_val,_,_ = multipletests(df_comp[\"p_value\"], method=\"fdr_bh\")\n",
    "\n",
    "        df_comp[\"adj_p_value\"] = adj_p_val\n",
    "\n",
    "        adj_results.append(df_comp)\n",
    "\n",
    "df_adj_tests = pd.concat(adj_results).reset_index(drop=True)\n",
    "\n",
    "df_adj_tests[df_adj_tests[\"adj_p_value\"]<0.05]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-) **Standard Deviation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "feat = \"std\"\n",
    "\n",
    "for df_comp in Utils.group_by(df_feat_std_norm, col=\"comp\", val=components):\n",
    "\n",
    "    tgt_feat_pre, tgt_feat_post = Utils.group_by(df_comp, col=\"instante\", val=[\"PRE\",\"POST\"])\n",
    "    tgt_feat_pre, tgt_feat_post = Utils.select_common_ids(tgt_feat_pre, tgt_feat_post)\n",
    "\n",
    "    feat_pre_ctrl, feat_pre_plcb, feat_pre_exp = Utils.group_by(tgt_feat_pre, col=\"grupo\", val=grupos)\n",
    "    feat_post_ctrl, feat_post_plcb, feat_post_exp = Utils.group_by(tgt_feat_post, col=\"grupo\", val=grupos)\n",
    "\n",
    "    pre = dict(zip(grupos, Utils.group_by(tgt_feat_pre, col=\"grupo\", val=grupos)))\n",
    "    post = dict(zip(grupos, Utils.group_by(tgt_feat_post, col=\"grupo\", val=grupos)))\n",
    "\n",
    "    df = compute_paired_test(pre, post, feat, channels, flag=\"wilcoxon\")\n",
    "\n",
    "    results.append(df)\n",
    "\n",
    "df_tests = pd.concat(results).reset_index(drop=True)\n",
    "\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "adj_results = []\n",
    "\n",
    "for df in Utils.group_by(df_tests, col=\"grupo\", val=grupos):\n",
    "\n",
    "    for df_comp in Utils.group_by(df, col=\"comp\", val=components):\n",
    "\n",
    "        _,adj_p_val,_,_ = multipletests(df_comp[\"p_value\"], method=\"fdr_bh\")\n",
    "\n",
    "        df_comp[\"adj_p_value\"] = adj_p_val\n",
    "\n",
    "        adj_results.append(df_comp)\n",
    "\n",
    "df_adj_tests = pd.concat(adj_results).reset_index(drop=True)\n",
    "\n",
    "df_adj_tests[df_adj_tests[\"adj_p_value\"]<0.05]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximation entropy\n",
    "\n",
    "La entropía de aproximación es una medida que nos dice cómo de predecible o caótico es un conjunto de datos. Se usa mucho en el análisis de señales biológicas (ondas cerebrales) y en series temporales en general.\n",
    "\n",
    "Partimos de una serie temporal con diferentes fluctuaciones que reflejan actividad eléctrica. Si las fluctuaciones siguen un patró claro y repetitivo, la entropía de aproximación será baja, porque es fácil de predecir. En cambio, si los números parecen aleatorios y desordenados, la entropía de aproximación será alta, porque hay mucha incertidumbre sobre el siguiente valor.  \n",
    "\n",
    "- Baja entropía de aproximación --> Más regularidad y menos caos.\n",
    "- Alta entropía de aproximación --> Más aleatoriedad y menos predecible.\n",
    "\n",
    "Este tipo de aproximación es una adaptación de la entropía de Shannon enfocada en series temporales.\n",
    "\n",
    "¿Por qué usamos la distancia máxima?\n",
    "\n",
    "La idea principal es asegurarnos de que todas las posiciones dentro de una subsecuencia sean similares para que dos patrones sean considerados equivalentes. Si tomáramos la diferencia promedio entre cada punto de las subsecuencias, podríamos perder información. Puede ser que la diferencia promedio enmascare parejas de puntos con una gran diferencia entre sí, lo que sugiere que esa pareja de secuencias no deberían ser consideradas similares.\n",
    "\n",
    "- Si dos secuencias tienen una sola posición con una gran diferencia, no deberían considerarse equivalentes, ya que la señal no se está comportando de manera predecible.\n",
    "\n",
    "Ejemplo con audio:\n",
    "\n",
    "Si comparamos fragmentos de una canción y en dos fragmentos todas las notas son casi iguales excepto una, esa única diferencia puede hacer que el audio suene muy distinto. La distancia máxima nos ayuda a capturar esos cambios bruscos.\n",
    "\n",
    "La **entropía de aproximación (ApEn)** se calcula como la diferencia entre dos funciones $\\phi(m, r)$:\n",
    "\n",
    "\n",
    "$$ApEn(m, r) = \\phi(m, r) - \\phi(m+1, r),\\ where:$$\n",
    "\n",
    "\n",
    "$$\\phi(m, r) = \\frac{1}{N - m + 1} \\sum_{i=1}^{N-m+1} \\log C^{m}_{i}$$\n",
    "\n",
    "En esta fórmula:\n",
    "- $m$ es el tamaño del patrón.\n",
    "- $r$ es la tolerancia, generalmente un múltiplo de la desviación estándar de la serie.\n",
    "- $C^{m}_{i}$ es la proporción de patrones similares de la secuencia $i$.\n",
    "- $N$ es la longitud total de la serie de tiempo.\n",
    "\n",
    "Ejemplos:\n",
    "- *Stationarity assessment of resting state condition via permutation entropy on EEG recordings* [https://doi.org/10.1038/s41598-024-82089-0]\n",
    "- *Entropy modulation of electroencephalographic signals in physiological aging* [https://doi.org/10.1016/j.mad.2021.111472]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Header with info:\",info)\n",
    "print(\"Channels:\",channels)\n",
    "print(\"Components:\",components)\n",
    "grupos = [\"CONTROL\", \"PLCB\", \"EXP\"]\n",
    "best_channels = list(set(channels) ^ set(['P8','T8', 'P4', 'O1', 'Oz', 'O2', 'Pz', 'P3', 'T7', 'P7']))  # Operador XOR (^) en conjuntos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full-Band window\n",
    "\n",
    "Hay sujetos en los grupos con valores de entropía exageradamente altos. Deben ser outliers. Esa es la razón por la que en las gráficas aparecen los nodos con un rojo intenso y no sale significativo el test. No creo que removerlos sea buena idea. En el rango completo de frecuencias [Target-All] se ve bien el efecto. En los ritmos cerebrales hay posibles outliers.\n",
    "\n",
    "- **Target**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta del archivo que deseas comprobar\n",
    "file_path = \"apEn_tgt.csv\"\n",
    "\n",
    "# Comprobar si el archivo existe\n",
    "if os.path.exists(file_path):\n",
    "    print(f\"El archivo '{file_path}' existe.\")\n",
    "else:\n",
    "    print(f\"El archivo '{file_path}' no existe.\")\n",
    "    print()\n",
    "\n",
    "    # Guardamos todos los DataFrames en una lista\n",
    "    list_dfs = [df_tgt_pre_ctrl, df_tgt_pre_plcb, df_tgt_pre_exp, df_tgt_post_ctrl, df_tgt_post_plcb, df_tgt_post_exp]\n",
    "\n",
    "    # Calculamos y guardamos la entropia por aproximacion\n",
    "    Entropy.get_apEn_dataframe(list_dfs, channels, components).to_csv(\"apEn_tgt.csv\",index=False,sep=';')\n",
    "\n",
    "# Cargamos los datos en un DataFrame\n",
    "df_tgt_apEn = pd.read_csv(\"apEn_tgt.csv\", header=0, delimiter=';')\n",
    "\n",
    "# Seleccionamos la entropia de aproximacion por instante\n",
    "apEn_pre, apEn_post = Utils.group_by(df_tgt_apEn[df_tgt_apEn['comp']=='all'], col=\"instante\", val=[\"PRE\",\"POST\"])\n",
    "\n",
    "# Seleccionamos la entropia de aproximacion por instante y de todo el estimulo (all).\n",
    "apEn_pre_ctrl, apEn_pre_plcb, apEn_pre_exp = Utils.group_by(apEn_pre, col=\"grupo\", val=grupos)\n",
    "apEn_post_ctrl, apEn_post_plcb, apEn_post_exp = Utils.group_by(apEn_post, col=\"grupo\", val=grupos)\n",
    "\n",
    "def get_channels(df1, df0):\n",
    "    # Definimos DataFrame para las diferencias \n",
    "    # de entropia (POST-PRE) de cada sujeto y canal\n",
    "    df0_ch = pd.DataFrame([], columns=df0['ch'].unique())\n",
    "    df1_ch = pd.DataFrame([], columns=df1['ch'].unique())\n",
    "\n",
    "    for (n,id),df0_id in df0.groupby(['n_test','id']):\n",
    "\n",
    "        # Seleccionamos las mismas filas en ambos DataFrames\n",
    "        df1_id = df1[(df1['n_test']==n)&(df1['id']==id)]\n",
    "\n",
    "        df0_ch.loc[len(df0_ch)] = df0_id['H'].values\n",
    "        df1_ch.loc[len(df1_ch)] = df1_id['H'].values\n",
    "\n",
    "    return df1_ch, df0_ch\n",
    "\n",
    "\n",
    "post_ctrl, pre_ctrl = get_channels(apEn_post_ctrl, apEn_pre_ctrl)\n",
    "\n",
    "post_plcb, pre_plcb = get_channels(apEn_post_plcb, apEn_pre_plcb)\n",
    "\n",
    "post_exp, pre_exp = get_channels(apEn_post_exp, apEn_pre_exp)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "vmax = np.max([np.max(pre_ctrl), np.max(pre_plcb), np.max(pre_exp)])\n",
    "vmin = np.min([np.min(pre_ctrl), np.min(pre_plcb), np.min(pre_exp)])\n",
    "centro = np.median([np.median(pre_ctrl), np.median(pre_plcb), np.median(pre_exp)])\n",
    "\n",
    "# Crear los heatmaps\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "sns.heatmap(pre_ctrl, ax=axes[0], cmap=\"coolwarm\", cbar=True, center=centro, vmax=vmax, vmin=vmin)\n",
    "axes[0].set_title(\"Electrodos - Pre - CTRL\")\n",
    "\n",
    "sns.heatmap(post_ctrl, ax=axes[1], cmap=\"coolwarm\", cbar=True,center=centro, vmax=vmax, vmin=vmin)\n",
    "axes[1].set_title(\"Electrodos - Post - CTRL\")\n",
    "\n",
    "percent_change = (post_ctrl - pre_ctrl) / pre_ctrl  # Convertir a %\n",
    "\n",
    "sns.barplot(x=pre_ctrl.columns, y=np.median(percent_change,axis=0)*100, ax=axes[2], color=\"steelblue\")\n",
    "axes[2].set_title(\"Cambio Mediano (%) por Electrodo\")\n",
    "axes[2].set_xlabel(\"Electrodos\")\n",
    "axes[2].set_ylabel(\"Cambio (%)\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "sns.heatmap(pre_plcb, ax=axes[0], cmap=\"coolwarm\", cbar=True, center=centro, vmax=vmax, vmin=vmin)\n",
    "axes[0].set_title(\"Electrodos - Pre - PLCB\")\n",
    "\n",
    "sns.heatmap(post_plcb, ax=axes[1], cmap=\"coolwarm\", cbar=True,center=centro, vmax=vmax, vmin=vmin)\n",
    "axes[1].set_title(\"Electrodos - Post - PLCB\")\n",
    "\n",
    "percent_change = (post_plcb - pre_plcb) / pre_plcb  # Convertir a %\n",
    "\n",
    "sns.barplot(x=pre_plcb.columns, y=np.median(percent_change,axis=0)*100, ax=axes[2], color=\"steelblue\")\n",
    "axes[2].set_title(\"Cambio Mediano (%) por Electrodo\")\n",
    "axes[2].set_xlabel(\"Electrodos\")\n",
    "axes[2].set_ylabel(\"Cambio (%)\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "sns.heatmap(pre_exp, ax=axes[0], cmap=\"coolwarm\", cbar=True, center=centro, vmax=vmax, vmin=vmin)\n",
    "axes[0].set_title(\"Electrodos - Pre - EXP\")\n",
    "\n",
    "sns.heatmap(post_exp, ax=axes[1], cmap=\"coolwarm\", cbar=True,center=centro, vmax=vmax, vmin=vmin)\n",
    "axes[1].set_title(\"Electrodos - Post - EXP\")\n",
    "percent_change = (post_exp - pre_exp) / pre_exp  # Convertir a %\n",
    "\n",
    "sns.barplot(x=pre_exp.columns, y=np.median(percent_change,axis=0)*100, ax=axes[2], color=\"steelblue\")\n",
    "axes[2].set_title(\"Cambio Mediano (%) por Electrodo\")\n",
    "axes[2].set_xlabel(\"Electrodos\")\n",
    "axes[2].set_ylabel(\"Cambio (%)\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# diff_plcb = Entropy.compute_diff(apEn_post_plcb, apEn_pre_plcb)\n",
    "\n",
    "# diff_exp = Entropy.compute_diff(apEn_post_exp, apEn_pre_exp)\n",
    "\n",
    "\n",
    "# # Calculamos la diferencia mediana por electrodo en cada grupo\n",
    "\n",
    "# # Approximation entropy: [ctrl_array, plcb_array, exp_array]\n",
    "# apEn_arrays = [diff_ctrl.median(), diff_plcb.median(), diff_exp.median()]\n",
    "\n",
    "# # Ploteamos diferencias\n",
    "# Entropy.plot_diff(apEn_arrays, electrodes, title = \"Target-All\", subtitles = [\"CTRL\",\"PLCB\",\"EXP\"])\n",
    "\n",
    "# # Corremos estadisticos \n",
    "# dict_apEn = {'CTRL': [apEn_pre_ctrl, apEn_post_ctrl],\n",
    "#              'PLCB': [apEn_pre_plcb, apEn_post_plcb],\n",
    "#              'EXP': [apEn_pre_exp, apEn_post_exp]} \n",
    "\n",
    "# pre = dict(zip(grupos, Utils.group_by(apEn_pre, col=\"grupo\", val=grupos)))\n",
    "# post = dict(zip(grupos, Utils.group_by(apEn_post, col=\"grupo\", val=grupos)))   \n",
    "\n",
    "# # Guardamos los resultados de los test pareados\n",
    "# stats_results = Entropy.compute_paired_test(pre, post, channels, \"wilcoxon\")\n",
    "\n",
    "# stats_results[(stats_results['p_value']<0.05)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp = 'all'\n",
    "\n",
    "# CTRL = {'PRE': Entropy.combine_channels(apEn_pre_ctrl, eeg_regions).values(),\n",
    "#         'POST': Entropy.combine_channels(apEn_post_ctrl, eeg_regions).values()}\n",
    "\n",
    "# PLCB = {'PRE': Entropy.combine_channels(apEn_pre_plcb, eeg_regions).values(),\n",
    "#        'POST': Entropy.combine_channels(apEn_post_plcb, eeg_regions).values()}\n",
    "\n",
    "# EXP = {'PRE': Entropy.combine_channels(apEn_pre_exp, eeg_regions).values(),\n",
    "#        'POST': Entropy.combine_channels(apEn_post_exp, eeg_regions).values()}\n",
    "\n",
    "# Entropy.plot_by_regions(CTRL, PLCB, EXP, eeg_regions.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparando los instantes PRE y POST dentro del grupo **CTRL**, podemos ver que su respuesta al estímulo se vuelve **más caótica e impredecible**.\n",
    "- Comparando los instantes PRE y POST dentro del grupo **PLCB**, podemos ver que su respuesta al estímulo se vuelve **más ordenada y predecible**.\n",
    "- Comparando los instantes PRE y POST dentro del grupo **EXP**, podemos ver que su respuesta al estímulo se mantiene **constante** en términos de entropía."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cerebral-bands: $\\delta$ - $\\theta$ - $\\alpha$ - $\\beta$\n",
    "\n",
    "- **Target**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta del archivo que deseas comprobar\n",
    "file_paths = {\"delta\": \"./cerebral_bands/apEn_tgt_delta.csv\",\n",
    "             \"theta\": \"./cerebral_bands/apEn_tgt_theta.csv\",\n",
    "             \"alpha\": \"./cerebral_bands/apEn_tgt_alpha.csv\",\n",
    "             \"beta\": \"./cerebral_bands/apEn_tgt_beta.csv\"}\n",
    "\n",
    "# Parametros de cada banda a analizar\n",
    "params = {\"delta\": {'lowcut':1,'highcut':4,'fs':500},\n",
    "          \"theta\": {'lowcut':4,'highcut':8,'fs':500},\n",
    "          \"alpha\": {'lowcut':8,'highcut':12,'fs':500},\n",
    "          \"beta\": {'lowcut':12,'highcut':30,'fs':500}}\n",
    "\n",
    "# Para cada banda de interes, then:\n",
    "for band, path in file_paths.items():\n",
    "    # Comprobar si el archivo existe\n",
    "    if os.path.exists(path):\n",
    "        print(f\"El archivo '{path}' existe.\")\n",
    "    else:\n",
    "        print(f\"El archivo '{path}' no existe.\")\n",
    "        print()\n",
    "\n",
    "        # Guardamos todos los DataFrames en una lista\n",
    "        list_dfs = [df_tgt_pre_ctrl, df_tgt_pre_plcb, df_tgt_pre_exp, df_tgt_post_ctrl, df_tgt_post_plcb, df_tgt_post_exp]\n",
    "        # Guardamos los valores de entropia en un DataFrame\n",
    "        Entropy.get_apEn_dataframe(list_dfs, channels, ['all'], params[band]).to_csv(path, index=False, sep=';')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Delta**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los datos en un DataFrame\n",
    "df_delta = pd.read_csv(\"./cerebral_bands/apEn_tgt_delta.csv\", header=0, delimiter=';')\n",
    "\n",
    "# Seleccionamos la entropia de aproximacion por instante\n",
    "apEn_pre, apEn_post = Utils.group_by(df_delta[df_delta['comp']=='all'], col=\"instante\", val=[\"PRE\",\"POST\"])\n",
    "\n",
    "# Seleccionamos la entropia de aproximacion por instante y de todo el estimulo (all).\n",
    "apEn_pre_ctrl, apEn_pre_plcb, apEn_pre_exp = Utils.group_by(apEn_pre, col=\"grupo\", val=grupos)\n",
    "apEn_post_ctrl, apEn_post_plcb, apEn_post_exp = Utils.group_by(apEn_post, col=\"grupo\", val=grupos)\n",
    "\n",
    "\n",
    "\n",
    "post_ctrl, pre_ctrl = get_channels(apEn_post_ctrl, apEn_pre_ctrl)\n",
    "\n",
    "post_plcb, pre_plcb = get_channels(apEn_post_plcb, apEn_pre_plcb)\n",
    "\n",
    "post_exp, pre_exp = get_channels(apEn_post_exp, apEn_pre_exp)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "vmax = np.max([np.max(pre_ctrl), np.max(pre_plcb), np.max(pre_exp)])\n",
    "vmin = np.min([np.min(pre_ctrl), np.min(pre_plcb), np.min(pre_exp)])\n",
    "centro = np.median([np.median(pre_ctrl), np.median(pre_plcb), np.median(pre_exp)])\n",
    "\n",
    "# Crear los heatmaps\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "sns.heatmap(pre_ctrl, ax=axes[0], cmap=\"coolwarm\", cbar=True, center=centro, vmax=vmax, vmin=vmin)\n",
    "axes[0].set_title(\"Electrodos - Pre\")\n",
    "\n",
    "sns.heatmap(post_ctrl, ax=axes[1], cmap=\"coolwarm\", cbar=True,center=centro, vmax=vmax, vmin=vmin)\n",
    "axes[1].set_title(\"Electrodos - Post\")\n",
    "\n",
    "percent_change = (post_ctrl - pre_ctrl) / pre_ctrl  # Convertir a %\n",
    "\n",
    "sns.barplot(x=pre_ctrl.columns, y=np.median(percent_change,axis=0)*100, ax=axes[2], color=\"steelblue\")\n",
    "axes[2].set_title(\"Cambio Mediano (%) por Electrodo\")\n",
    "axes[2].set_xlabel(\"Electrodos\")\n",
    "axes[2].set_ylabel(\"Cambio (%)\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "sns.heatmap(pre_plcb, ax=axes[0], cmap=\"coolwarm\", cbar=True, center=centro, vmax=vmax, vmin=vmin)\n",
    "axes[0].set_title(\"Electrodos - Pre\")\n",
    "\n",
    "sns.heatmap(post_plcb, ax=axes[1], cmap=\"coolwarm\", cbar=True,center=centro, vmax=vmax, vmin=vmin)\n",
    "axes[1].set_title(\"Electrodos - Post\")\n",
    "\n",
    "percent_change = (post_plcb - pre_plcb) / pre_plcb  # Convertir a %\n",
    "\n",
    "sns.barplot(x=pre_plcb.columns, y=np.median(percent_change,axis=0)*100, ax=axes[2], color=\"steelblue\")\n",
    "axes[2].set_title(\"Cambio Mediano (%) por Electrodo\")\n",
    "axes[2].set_xlabel(\"Electrodos\")\n",
    "axes[2].set_ylabel(\"Cambio (%)\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "sns.heatmap(pre_exp, ax=axes[0], cmap=\"coolwarm\", cbar=True, center=centro, vmax=vmax, vmin=vmin)\n",
    "axes[0].set_title(\"Electrodos - Pre\")\n",
    "\n",
    "sns.heatmap(post_exp, ax=axes[1], cmap=\"coolwarm\", cbar=True,center=centro, vmax=vmax, vmin=vmin)\n",
    "axes[1].set_title(\"Electrodos - Post\")\n",
    "percent_change = (post_exp - pre_exp) / pre_exp  # Convertir a %\n",
    "\n",
    "sns.barplot(x=pre_exp.columns, y=np.median(percent_change,axis=0)*100, ax=axes[2], color=\"steelblue\")\n",
    "axes[2].set_title(\"Cambio Mediano (%) por Electrodo\")\n",
    "axes[2].set_xlabel(\"Electrodos\")\n",
    "axes[2].set_ylabel(\"Cambio (%)\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# # Calculamos la diferencia de apEn entre POST-PRE\n",
    "# diff_ctrl = Entropy.compute_diff(apEn_post_ctrl, apEn_pre_ctrl)\n",
    "\n",
    "# diff_plcb = Entropy.compute_diff(apEn_post_plcb, apEn_pre_plcb)\n",
    "\n",
    "# diff_exp = Entropy.compute_diff(apEn_post_exp, apEn_pre_exp)\n",
    "\n",
    "# # Calculamos la diferencia mediana por electrodo en cada grupo\n",
    "\n",
    "# # Approximation entropy: [ctrl_array, plcb_array, exp_array]\n",
    "# apEn_arrays = [diff_ctrl.median(), diff_plcb.median(), diff_exp.median()]\n",
    "\n",
    "# # Ploteamos diferencias\n",
    "# Entropy.plot_diff(apEn_arrays, electrodes, title = \"Target-Delta\", subtitles = [\"CTRL\",\"PLCB\",\"EXP\"])\n",
    "\n",
    "# # Corremos estadisticos \n",
    "# dict_apEn = {'CTRL': [apEn_pre_ctrl, apEn_post_ctrl],\n",
    "#              'PLCB': [apEn_pre_plcb, apEn_post_plcb],\n",
    "#              'EXP': [apEn_pre_exp, apEn_post_exp]} \n",
    "\n",
    "# pre = dict(zip(grupos, Utils.group_by(apEn_pre, col=\"grupo\", val=grupos)))\n",
    "# post = dict(zip(grupos, Utils.group_by(apEn_post, col=\"grupo\", val=grupos)))  \n",
    "\n",
    "# # Guardamos los resultados de los test pareados\n",
    "# stats_results = Entropy.compute_paired_test(pre, post, channels, \"wilcoxon\")\n",
    "\n",
    "# stats_results[(stats_results['p_value']<0.05)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp = 'all'\n",
    "\n",
    "# CTRL = {'PRE': Entropy.combine_channels(apEn_pre_ctrl, eeg_regions).values(),\n",
    "#         'POST': Entropy.combine_channels(apEn_post_ctrl, eeg_regions).values()}\n",
    "\n",
    "# PLCB = {'PRE': Entropy.combine_channels(apEn_pre_plcb, eeg_regions).values(),\n",
    "#        'POST': Entropy.combine_channels(apEn_post_plcb, eeg_regions).values()}\n",
    "\n",
    "# EXP = {'PRE': Entropy.combine_channels(apEn_pre_exp, eeg_regions).values(),\n",
    "#        'POST': Entropy.combine_channels(apEn_post_exp, eeg_regions).values()}\n",
    "\n",
    "# Entropy.plot_by_regions(CTRL, PLCB, EXP, eeg_regions.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al comparar los instantes PRE y POST, los 3 grupos presentan una respuesta al estímulo **más caótica e impredecible** en la banda de frecuencia **Delta**.\n",
    "- PLCB > CTRL > EXP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Theta**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los datos en un DataFrame\n",
    "df_theta = pd.read_csv(\"./cerebral_bands/apEn_tgt_theta.csv\", header=0, delimiter=';')\n",
    "\n",
    "# Seleccionamos la entropia de aproximacion por instante\n",
    "apEn_pre, apEn_post = Utils.group_by(df_theta[df_theta['comp']=='all'], col=\"instante\", val=[\"PRE\",\"POST\"])\n",
    "\n",
    "# Seleccionamos la entropia de aproximacion por instante y de todo el estimulo (all).\n",
    "apEn_pre_ctrl, apEn_pre_plcb, apEn_pre_exp = Utils.group_by(apEn_pre, col=\"grupo\", val=grupos)\n",
    "apEn_post_ctrl, apEn_post_plcb, apEn_post_exp = Utils.group_by(apEn_post, col=\"grupo\", val=grupos)\n",
    "\n",
    "\n",
    "def get_channels(df1, df0):\n",
    "    # Definimos DataFrame para las diferencias \n",
    "    # de entropia (POST-PRE) de cada sujeto y canal\n",
    "    df0_ch = pd.DataFrame([], columns=df0['ch'].unique())\n",
    "    df1_ch = pd.DataFrame([], columns=df1['ch'].unique())\n",
    "\n",
    "    for (n,id),df0_id in df0.groupby(['n_test','id']):\n",
    "\n",
    "        # Seleccionamos las mismas filas en ambos DataFrames\n",
    "        df1_id = df1[(df1['n_test']==n)&(df1['id']==id)]\n",
    "\n",
    "        df0_ch.loc[len(df0_ch)] = df0_id['H'].values\n",
    "        df1_ch.loc[len(df1_ch)] = df1_id['H'].values\n",
    "\n",
    "    return df1_ch, df0_ch\n",
    "\n",
    "\n",
    "post_ctrl, pre_ctrl = get_channels(apEn_post_ctrl, apEn_pre_ctrl)\n",
    "\n",
    "post_plcb, pre_plcb = get_channels(apEn_post_plcb, apEn_pre_plcb)\n",
    "\n",
    "post_exp, pre_exp = get_channels(apEn_post_exp, apEn_pre_exp)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "vmax = np.max([np.max(pre_ctrl), np.max(pre_plcb), np.max(pre_exp)])\n",
    "vmin = np.min([np.min(pre_ctrl), np.min(pre_plcb), np.min(pre_exp)])\n",
    "centro = np.median([np.median(pre_ctrl), np.median(pre_plcb), np.median(pre_exp)])\n",
    "\n",
    "# Crear los heatmaps\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "sns.heatmap(pre_ctrl, ax=axes[0], cmap=\"coolwarm\", cbar=True, center=centro, vmax=vmax, vmin=vmin)\n",
    "axes[0].set_title(\"Electrodos - Pre\")\n",
    "\n",
    "sns.heatmap(post_ctrl, ax=axes[1], cmap=\"coolwarm\", cbar=True,center=centro, vmax=vmax, vmin=vmin)\n",
    "axes[1].set_title(\"Electrodos - Post\")\n",
    "\n",
    "percent_change = (post_ctrl - pre_ctrl) / pre_ctrl  # Convertir a %\n",
    "\n",
    "sns.barplot(x=pre_ctrl.columns, y=np.median(percent_change,axis=0)*100, ax=axes[2], color=\"steelblue\")\n",
    "axes[2].set_title(\"Cambio Mediano (%) por Electrodo\")\n",
    "axes[2].set_xlabel(\"Electrodos\")\n",
    "axes[2].set_ylabel(\"Cambio (%)\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "sns.heatmap(pre_plcb, ax=axes[0], cmap=\"coolwarm\", cbar=True, center=centro, vmax=vmax, vmin=vmin)\n",
    "axes[0].set_title(\"Electrodos - Pre\")\n",
    "\n",
    "sns.heatmap(post_plcb, ax=axes[1], cmap=\"coolwarm\", cbar=True,center=centro, vmax=vmax, vmin=vmin)\n",
    "axes[1].set_title(\"Electrodos - Post\")\n",
    "\n",
    "percent_change = (post_plcb - pre_plcb) / pre_plcb  # Convertir a %\n",
    "\n",
    "sns.barplot(x=pre_plcb.columns, y=np.median(percent_change,axis=0)*100, ax=axes[2], color=\"steelblue\")\n",
    "axes[2].set_title(\"Cambio Mediano (%) por Electrodo\")\n",
    "axes[2].set_xlabel(\"Electrodos\")\n",
    "axes[2].set_ylabel(\"Cambio (%)\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "sns.heatmap(pre_exp, ax=axes[0], cmap=\"coolwarm\", cbar=True, center=centro, vmax=vmax, vmin=vmin)\n",
    "axes[0].set_title(\"Electrodos - Pre\")\n",
    "\n",
    "sns.heatmap(post_exp, ax=axes[1], cmap=\"coolwarm\", cbar=True,center=centro, vmax=vmax, vmin=vmin)\n",
    "axes[1].set_title(\"Electrodos - Post\")\n",
    "percent_change = (post_exp - pre_exp) / pre_exp  # Convertir a %\n",
    "\n",
    "sns.barplot(x=pre_exp.columns, y=np.median(percent_change,axis=0)*100, ax=axes[2], color=\"steelblue\")\n",
    "axes[2].set_title(\"Cambio Mediano (%) por Electrodo\")\n",
    "axes[2].set_xlabel(\"Electrodos\")\n",
    "axes[2].set_ylabel(\"Cambio (%)\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# # Calculamos la diferencia de apEn entre POST-PRE\n",
    "# diff_ctrl = Entropy.compute_diff(apEn_post_ctrl, apEn_pre_ctrl)\n",
    "\n",
    "# diff_plcb = Entropy.compute_diff(apEn_post_plcb, apEn_pre_plcb)\n",
    "\n",
    "# diff_exp = Entropy.compute_diff(apEn_post_exp, apEn_pre_exp)\n",
    "\n",
    "# # Calculamos la diferencia mediana por electrodo en cada grupo\n",
    "\n",
    "# # Approximation entropy: [ctrl_array, plcb_array, exp_array]\n",
    "# apEn_arrays = [diff_ctrl.median(), diff_plcb.median(), diff_exp.median()]\n",
    "\n",
    "# # Ploteamos diferencias\n",
    "# Entropy.plot_diff(apEn_arrays, electrodes, title = \"Target-Theta\", subtitles = [\"CTRL\",\"PLCB\",\"EXP\"])\n",
    "\n",
    "# # Corremos estadisticos \n",
    "# dict_apEn = {'CTRL': [apEn_pre_ctrl, apEn_post_ctrl],\n",
    "#              'PLCB': [apEn_pre_plcb, apEn_post_plcb],\n",
    "#              'EXP': [apEn_pre_exp, apEn_post_exp]} \n",
    "\n",
    "# pre = dict(zip(grupos, Utils.group_by(apEn_pre, col=\"grupo\", val=grupos)))\n",
    "# post = dict(zip(grupos, Utils.group_by(apEn_post, col=\"grupo\", val=grupos)))   \n",
    "\n",
    "# # Guardamos los resultados de los test pareados\n",
    "# stats_results = Entropy.compute_paired_test(pre, post, channels, \"wilcoxon\")\n",
    "\n",
    "# stats_results[(stats_results['p_value']<0.05)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp = 'all'\n",
    "\n",
    "# CTRL = {'PRE': Entropy.combine_channels(apEn_pre_ctrl, eeg_regions).values(),\n",
    "#         'POST': Entropy.combine_channels(apEn_post_ctrl, eeg_regions).values()}\n",
    "\n",
    "# PLCB = {'PRE': Entropy.combine_channels(apEn_pre_plcb, eeg_regions).values(),\n",
    "#        'POST': Entropy.combine_channels(apEn_post_plcb, eeg_regions).values()}\n",
    "\n",
    "# EXP = {'PRE': Entropy.combine_channels(apEn_pre_exp, eeg_regions).values(),\n",
    "#        'POST': Entropy.combine_channels(apEn_post_exp, eeg_regions).values()}\n",
    "\n",
    "# Entropy.plot_by_regions(CTRL, PLCB, EXP, eeg_regions.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al comparar los instantes PRE y POST dentro de los grupos **PLCB** y **EXP**, presentan respuestas más **caóticas e impredecibles** en la banda **Theta**. En cambio, el grupo **CTRL** se mantiene constante.\n",
    "- PLCB > EXP > CTRL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Alpha**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los datos en un DataFrame\n",
    "df_alpha = pd.read_csv(\"./cerebral_bands/apEn_tgt_alpha.csv\", header=0, delimiter=';')\n",
    "\n",
    "# Seleccionamos la entropia de aproximacion por instante\n",
    "apEn_pre, apEn_post = Utils.group_by(df_alpha[df_alpha['comp']=='all'], col=\"instante\", val=[\"PRE\",\"POST\"])\n",
    "\n",
    "# Seleccionamos la entropia de aproximacion por instante y de todo el estimulo (all).\n",
    "apEn_pre_ctrl, apEn_pre_plcb, apEn_pre_exp = Utils.group_by(apEn_pre, col=\"grupo\", val=grupos)\n",
    "apEn_post_ctrl, apEn_post_plcb, apEn_post_exp = Utils.group_by(apEn_post, col=\"grupo\", val=grupos)\n",
    "\n",
    "# Calculamos la diferencia de apEn entre POST-PRE\n",
    "diff_ctrl = Entropy.compute_diff(apEn_post_ctrl, apEn_pre_ctrl)\n",
    "\n",
    "diff_plcb = Entropy.compute_diff(apEn_post_plcb, apEn_pre_plcb)\n",
    "\n",
    "diff_exp = Entropy.compute_diff(apEn_post_exp, apEn_pre_exp)\n",
    "\n",
    "# Calculamos la diferencia mediana por electrodo en cada grupo\n",
    "\n",
    "# Approximation entropy: [ctrl_array, plcb_array, exp_array]\n",
    "apEn_arrays = [diff_ctrl.median(), diff_plcb.median(), diff_exp.median()]\n",
    "\n",
    "# Ploteamos diferencias\n",
    "Entropy.plot_diff(apEn_arrays, electrodes, title = \"Target-Alpha\", subtitles = [\"CTRL\",\"PLCB\",\"EXP\"])\n",
    "\n",
    "# Corremos estadisticos \n",
    "dict_apEn = {'CTRL': [apEn_pre_ctrl, apEn_post_ctrl],\n",
    "             'PLCB': [apEn_pre_plcb, apEn_post_plcb],\n",
    "             'EXP': [apEn_pre_exp, apEn_post_exp]} \n",
    "\n",
    "pre = dict(zip(grupos, Utils.group_by(apEn_pre, col=\"grupo\", val=grupos)))\n",
    "post = dict(zip(grupos, Utils.group_by(apEn_post, col=\"grupo\", val=grupos)))   \n",
    "\n",
    "# Guardamos los resultados de los test pareados\n",
    "stats_results = Entropy.compute_paired_test(pre, post, channels, \"wilcoxon\")\n",
    "\n",
    "stats_results[(stats_results['p_value']<0.05)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp = 'all'\n",
    "\n",
    "# CTRL = {'PRE': Entropy.combine_channels(apEn_pre_ctrl, eeg_regions).values(),\n",
    "#         'POST': Entropy.combine_channels(apEn_post_ctrl, eeg_regions).values()}\n",
    "\n",
    "# PLCB = {'PRE': Entropy.combine_channels(apEn_pre_plcb, eeg_regions).values(),\n",
    "#        'POST': Entropy.combine_channels(apEn_post_plcb, eeg_regions).values()}\n",
    "\n",
    "# EXP = {'PRE': Entropy.combine_channels(apEn_pre_exp, eeg_regions).values(),\n",
    "#        'POST': Entropy.combine_channels(apEn_post_exp, eeg_regions).values()}\n",
    "\n",
    "# Entropy.plot_by_regions(CTRL, PLCB, EXP, eeg_regions.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los 3 grupos se mantienen en constantes en la banda **Alpha**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Beta**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los datos en un DataFrame\n",
    "df_beta = pd.read_csv(\"./cerebral_bands/apEn_tgt_beta.csv\", header=0, delimiter=';')\n",
    "\n",
    "# Seleccionamos la entropia de aproximacion por instante\n",
    "apEn_pre, apEn_post = Utils.group_by(df_beta[df_beta['comp']=='all'], col=\"instante\", val=[\"PRE\",\"POST\"])\n",
    "\n",
    "# Seleccionamos la entropia de aproximacion por instante y de todo el estimulo (all).\n",
    "apEn_pre_ctrl, apEn_pre_plcb, apEn_pre_exp = Utils.group_by(apEn_pre, col=\"grupo\", val=grupos)\n",
    "apEn_post_ctrl, apEn_post_plcb, apEn_post_exp = Utils.group_by(apEn_post, col=\"grupo\", val=grupos)\n",
    "\n",
    "# Calculamos la diferencia de apEn entre POST-PRE\n",
    "diff_ctrl = Entropy.compute_diff(apEn_post_ctrl, apEn_pre_ctrl)\n",
    "\n",
    "diff_plcb = Entropy.compute_diff(apEn_post_plcb, apEn_pre_plcb)\n",
    "\n",
    "diff_exp = Entropy.compute_diff(apEn_post_exp, apEn_pre_exp)\n",
    "\n",
    "# Calculamos la diferencia mediana por electrodo en cada grupo\n",
    "\n",
    "# Approximation entropy: [ctrl_array, plcb_array, exp_array]\n",
    "apEn_arrays = [diff_ctrl.median(), diff_plcb.median(), diff_exp.median()]\n",
    "\n",
    "# Ploteamos diferencias\n",
    "Entropy.plot_diff(apEn_arrays, electrodes, title = \"Target-Beta\", subtitles = [\"CTRL\",\"PLCB\",\"EXP\"])\n",
    "\n",
    "# Corremos estadisticos \n",
    "dict_apEn = {'CTRL': [apEn_pre_ctrl, apEn_post_ctrl],\n",
    "             'PLCB': [apEn_pre_plcb, apEn_post_plcb],\n",
    "             'EXP': [apEn_pre_exp, apEn_post_exp]} \n",
    "\n",
    "pre = dict(zip(grupos, Utils.group_by(apEn_pre, col=\"grupo\", val=grupos)))\n",
    "post = dict(zip(grupos, Utils.group_by(apEn_post, col=\"grupo\", val=grupos)))   \n",
    "\n",
    "# Guardamos los resultados de los test pareados\n",
    "stats_results = Entropy.compute_paired_test(pre, post, eeg_regions, \"wilcoxon\")\n",
    "\n",
    "stats_results[(stats_results['p_value']<0.05)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp = 'all'\n",
    "\n",
    "# CTRL = {'PRE': Entropy.combine_channels(apEn_pre_ctrl, eeg_regions).values(),\n",
    "#         'POST': Entropy.combine_channels(apEn_post_ctrl, eeg_regions).values()}\n",
    "\n",
    "# PLCB = {'PRE': Entropy.combine_channels(apEn_pre_plcb, eeg_regions).values(),\n",
    "#        'POST': Entropy.combine_channels(apEn_post_plcb, eeg_regions).values()}\n",
    "\n",
    "# EXP = {'PRE': Entropy.combine_channels(apEn_pre_exp, eeg_regions).values(),\n",
    "#        'POST': Entropy.combine_channels(apEn_post_exp, eeg_regions).values()}\n",
    "\n",
    "# Entropy.plot_by_regions(CTRL, PLCB, EXP, eeg_regions.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al comparar los instantes PRE y POST dentro de los grupos **CTRL** y **EXP**, presentan respuestas más caóticas e impredecibles en la banda **Beta**. En cambio, el grupo **PLCB** se mantiene constante.\n",
    "- CTRL > EXP > PLCB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potencia espectral\n",
    "\n",
    "La potencia espectral cruzada es una medida que nos dice cómo están relacionadas dos señales mediante la energía que comparten en cada frecuencia. \n",
    "\n",
    "$$P_{XY}(f) = X(f)·Y^{*}(f)$$ \n",
    "\n",
    "- Donde:\n",
    "    - $X(f)$: son los componentes de la DFT correspondientes a $x[n]$.\n",
    "    - $Y(f)$: son los componentes conjugados de la DFT correspondientes a $y[n]$. \n",
    "\n",
    "Su demostración es posible mediante las propiedades de los números complejos en coordenadas polares, ya que cada componente de la DFT puede ser transformada de forma directa.\n",
    "\n",
    "- En coordenadas polares, se representa como:\n",
    "\n",
    "$$X(f) = |X(f)|·e^{i\\phi}$$\n",
    "\n",
    "Donde:\n",
    "- $|X(f)|$: es la magnitud.\n",
    "- $\\phi$: es la fase.\n",
    "\n",
    "La DFT toma una señal de $N$ puntos y devuelve $N$ valores complejos en el dominio de la frecuencia. Estos valores corresponden a $N$ frecuencias equiespaciadas, que van desde 0 Hz hasta $F_{s}$ Hz (frecuencia de muestreo). Sin embargo, no todas las frecuencias son únicas, ya que la distribución de sus valores es simétrica y solo nos interesan aquellas que van desde 0 Hz hasta $\\frac{F_{s}}{2}$ Hz (frecuencia de Nyquist).\n",
    "\n",
    "Esas componentes de frecuencia tienen la forma $Re + j·Im$ y pueden transformarse perfectamente en coordenadas polares $X(f) = |X(f)|·e^{i\\phi}$. \n",
    "\n",
    "La potencia espectral cruzada trata de combinar la información que refleja la magnitud y fase asociadas a cada frecuencia entre dos señales. \n",
    "\n",
    "En términos de magnitud, si multiplicamos la magnitud por cada par de frecuencias en ambas señales, los valores grandes se acentuarán y los demás se mantendrán en las mismas proporciones. Esto información permite resaltar de forma sencilla las frecuencias que poseen una magnitud significativa común.\n",
    "\n",
    "$$|X(f)|·|Y(f)|$$\n",
    "\n",
    "En términos de fase, la diferencia por cada par de frecuencias en ambas señales permite conocer su desfase o sincronización.\n",
    "\n",
    "$$\\phi_{X}-\\phi_{Y}$$\n",
    "\n",
    "A través de las propiedades de las potencias en coordenadas polares, la combinación de la magnitud y desfase es automática como se puede observar, a continuación:\n",
    "\n",
    "- Ejemplo:\n",
    "$$z_{x}=|z_{x}|·e^{i(\\phi_{x})}\\ y\\ z_{y}=|z_{y}|·e^{i(\\phi_{y})}$$\n",
    "\n",
    "$$z_{x}·z^{*}_{y} = |z_{x}|·|z_{y}|·e^{i(\\phi_{x}-\\phi_{y})}$$\n",
    "\n",
    "- Fórmula:\n",
    "\n",
    "$$P_{xy}(f)=X(f)·Y^{*}(f)=|X(f)|·|Y(f)|·e^{i(\\phi_{X}-\\phi_{Y})}$$\n",
    "\n",
    "## Spectral coherence\n",
    "\n",
    "La coherencia espectral es una medida que nos dice cuánto se parecen dos señales en cada frecuencia. Se puede entender como:\n",
    "\n",
    "- La proporción de la potencia de $y[n]$ que se explica por $x[n]$ en cada frecuencia $f$.\n",
    "- Normalización de la potencia espectral cruzada entre dos señales.\n",
    "\n",
    "\n",
    "$$C_{XY}(f) = \\frac{|P_{XY}(f)|^{2}}{P_{XX}(f)·P_{YY}(f)}$$\n",
    "\n",
    "- Donde:\n",
    "    - $P_{XY}(f)$: es la potencia espectral cruzada entre las señales $x[n]$ e $y[n]$.\n",
    "    - $P_{XX}(f)$: es la densidad espectral de potencia de la señal $x[n]$.\n",
    "    - $P_{YY}(f)$: es la densidad espectral de potencia de la señal $y[n]$.\n",
    "    - $C_{XY}(f)$: es la coherencia espectral que toma valores entre 0 y 1.\n",
    "\n",
    "\n",
    "\n",
    "La coherencia espectral mide la relación en el dominio de la frecuencia entre dos señales. Para hacerlo, la función *signal.coherence()*:\n",
    "\n",
    "- Divide la señal en segmentos (nperseg) de longitud determinada.\n",
    "\n",
    "- Aplica una FFT a cada segmento para obtener las frecuencias de cada segmento.\n",
    "\n",
    "- Luego, calcula las densidades espectrales y las densidades espectrales cruzadas para calcular la coherencia a través de un rango de frecuencias.\n",
    "\n",
    "La FFT realiza una transformada espectral que devuelve un rango de frecuencias, desde 0 Hz hasta Nyquist (la mitad de la frecuencia de muestreo, fs/2). La coherencia no solo mide la frecuencia de las señales, sino todas las frecuencias en las cuales hay componentes en las señales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths with files (.csv)\n",
    "path_tgt = \"E:/TFM/CLUSTERING_ALL_ICA_by_segments/ODDBALL/stimulus_tgt.csv\"\n",
    "path_std = \"E:/TFM/CLUSTERING_ALL_ICA_by_segments/ODDBALL/stimulus_std.csv\"\n",
    "\n",
    "# Load DataFrame for every type of stimulus\n",
    "df_w_tgt = pd.read_csv(path_tgt, header=0, delimiter=';')\n",
    "df_w_std = pd.read_csv(path_std, header=0, delimiter=';')\n",
    "\n",
    "# Common information about both DataFrames, where: df_std.columns == df_tgt.columns\n",
    "channels = df_w_std.columns[6:].to_list()\n",
    "info = df_w_std.columns[:6].to_list()\n",
    "components = df_w_std[\"comp\"].unique()\n",
    "\n",
    "# Seleccionamos instantes y grupos de TARGET DataFrames\n",
    "df_tgt_ctrl = df_w_tgt[df_w_tgt[\"grupo\"] == \"CONTROL\"]# select CTRL subjects\n",
    "df_tgt_plcb = df_w_tgt[df_w_tgt[\"grupo\"] == \"PLCB\"]# select PLCB subjects\n",
    "df_tgt_exp = df_w_tgt[df_w_tgt[\"grupo\"] == \"EXP\"]# select EXP subjects\n",
    "\n",
    "df_tgt_pre_ctrl = df_w_tgt[(df_w_tgt[\"instante\"]==\"PRE\")&(df_w_tgt[\"grupo\"]==\"CONTROL\")]\n",
    "df_tgt_pre_plcb = df_w_tgt[(df_w_tgt[\"instante\"]==\"PRE\")&(df_w_tgt[\"grupo\"]==\"PLCB\")]\n",
    "df_tgt_pre_exp = df_w_tgt[(df_w_tgt[\"instante\"]==\"PRE\")&(df_w_tgt[\"grupo\"]==\"EXP\")]\n",
    "\n",
    "df_tgt_post_ctrl = df_w_tgt[(df_w_tgt[\"instante\"]==\"POST\")&(df_w_tgt[\"grupo\"]==\"CONTROL\")]\n",
    "df_tgt_post_plcb = df_w_tgt[(df_w_tgt[\"instante\"]==\"POST\")&(df_w_tgt[\"grupo\"]==\"PLCB\")]\n",
    "df_tgt_post_exp = df_w_tgt[(df_w_tgt[\"instante\"]==\"POST\")&(df_w_tgt[\"grupo\"]==\"EXP\")]\n",
    "\n",
    "df_tgt_seg_ctrl = df_w_tgt[(df_w_tgt[\"instante\"]==\"SEGUIMIENTO\")&(df_w_tgt[\"grupo\"]==\"CONTROL\")]\n",
    "df_tgt_seg_plcb = df_w_tgt[(df_w_tgt[\"instante\"]==\"SEGUIMIENTO\")&(df_w_tgt[\"grupo\"]==\"PLCB\")]\n",
    "df_tgt_seg_exp = df_w_tgt[(df_w_tgt[\"instante\"]==\"SEGUIMIENTO\")&(df_w_tgt[\"grupo\"]==\"EXP\")]\n",
    "\n",
    "# Seleccionamos sujetos comunes entre instantes\n",
    "df_tgt_pre_ctrl,df_tgt_post_ctrl = Utils.select_common_ids(df_tgt_pre_ctrl, df_tgt_post_ctrl)\n",
    "df_tgt_pre_plcb,df_tgt_post_plcb = Utils.select_common_ids(df_tgt_pre_plcb, df_tgt_post_plcb)\n",
    "df_tgt_pre_exp,df_tgt_post_exp = Utils.select_common_ids(df_tgt_pre_exp, df_tgt_post_exp)\n",
    "\n",
    "print(\"Header with info:\",info)\n",
    "print(\"Channels:\",channels)\n",
    "print(\"Components:\",components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las bandas cerebrales (en Hz)\n",
    "dict_bands = {\n",
    "    'all': (1, 30),\n",
    "    'delta': (1, 4),\n",
    "    'theta': (4, 8),\n",
    "    'alpha': (8, 12),\n",
    "    'beta': (12, 30)}\n",
    "\n",
    "diff_tgt_coherence = {}\n",
    "\n",
    "for band, freqs in dict_bands.items():\n",
    "\n",
    "    # Compute coherence matrix for every subject between every pair of channels\n",
    "    coherence_pre_ctrl = Coherence.compute_matrix(df_tgt_pre_ctrl, channels, 'all', fs=500, nperseg=225, band_range=freqs)\n",
    "    coherence_post_ctrl = Coherence.compute_matrix(df_tgt_post_ctrl, channels, 'all', fs=500, nperseg=225, band_range=freqs)\n",
    "\n",
    "    # Check if subjects are correctly ordered and each pair has the same number of values\n",
    "    Coherence.check_consistency(coherence_pre_ctrl, coherence_post_ctrl)\n",
    "\n",
    "    # Compute coherence matrix for every subject between every pair of channels\n",
    "    coherence_pre_plcb = Coherence.compute_matrix(df_tgt_pre_plcb, channels, 'all', fs=500, nperseg=225, band_range=freqs)\n",
    "    coherence_post_plcb = Coherence.compute_matrix(df_tgt_post_plcb, channels, 'all', fs=500, nperseg=225, band_range=freqs)\n",
    "\n",
    "    # Check if subjects are correctly ordered and each pair has the same number of values\n",
    "    Coherence.check_consistency(coherence_pre_plcb, coherence_post_plcb)\n",
    "\n",
    "    # Compute coherence matrix for every subject between every pair of channels\n",
    "    coherence_pre_exp = Coherence.compute_matrix(df_tgt_pre_exp, channels, 'all', fs=500, nperseg=225, band_range=freqs)\n",
    "    coherence_post_exp = Coherence.compute_matrix(df_tgt_post_exp, channels, 'all', fs=500, nperseg=225, band_range=freqs)\n",
    "\n",
    "    # Check if subjects are correctly ordered and each pair has the same number of values \n",
    "    Coherence.check_consistency(coherence_pre_exp, coherence_post_exp)\n",
    "\n",
    "    # Compute POST - PRE differences between each pair of coherence matrices\n",
    "    diff_ctrl = Coherence.get_diff(coherence_post_ctrl, coherence_pre_ctrl)\n",
    "    diff_plcb = Coherence.get_diff(coherence_post_plcb, coherence_pre_plcb)\n",
    "    diff_exp = Coherence.get_diff(coherence_post_exp, coherence_pre_exp)\n",
    "\n",
    "    # Calculamos la matriz mediana de todos los controles, placebos y experimentales\n",
    "    diff_tgt_coherence[band] = [np.median(diff_ctrl, axis=0), np.median(diff_plcb, axis=0), np.median(diff_exp, axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Coherence.plot_diff(diff_tgt_coherence[\"all\"], channels, titles = [\"Target\", \"All\", \"CTRL\",\"PLCB\",\"EXP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Coherence.plot_diff(diff_tgt_coherence[\"delta\"], channels, titles = [\"Target\", \"Delta\", \"CTRL\",\"PLCB\",\"EXP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Coherence.plot_diff(diff_tgt_coherence[\"theta\"], channels, titles = [\"Target\", \"Theta\", \"CTRL\",\"PLCB\",\"EXP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Coherence.plot_diff(diff_tgt_coherence[\"alpha\"], channels, titles = [\"Target\", \"Alpha\", \"CTRL\",\"PLCB\",\"EXP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Coherence.plot_diff(diff_tgt_coherence[\"beta\"], channels, titles = [\"Target\", \"Beta\", \"CTRL\",\"PLCB\",\"EXP\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(sync_matrix, channels, electrodes, title=\"TITLE\", subtitle=[\"CTRL\",\"PLCB\",\"EXP\"]):\n",
    "\n",
    "    circunferencias = np.arange(0, 1.5, 0.2)\n",
    "    vmin = min(matrix.min() for matrix in sync_matrix)  # Encuentra el minimo global\n",
    "    vmax = max(matrix.max() for matrix in sync_matrix)  # Encuentra el maximo global\n",
    "    vmax = max(abs(vmin), abs(vmax))\n",
    "    vmin = -vmax\n",
    "    cut_off = np.median(np.abs(sync_matrix))\n",
    "\n",
    "    # Dibujar los nodos\n",
    "    x_coords, y_coords = zip(*electrodes.values())\n",
    "\n",
    "    # Crear una figura con 1 fila y 4 columnas\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(18, 6), gridspec_kw={\"width_ratios\": [1, 1, 1, 0.05]})\n",
    "\n",
    "    # Colocamos Titulo de la figura\n",
    "    plt.suptitle('['+title+']'+r' Neural Response Graph ($\\Delta$ POST-PRE)', fontsize=16)\n",
    "\n",
    "    # Por cada eje o subplot\n",
    "    for k, ax in enumerate(axes[:-1]):\n",
    "\n",
    "        # Dibujamos aristas como nivel de coherencia\n",
    "        for i in range(len(channels)):\n",
    "            for j in range(i + 1, len(channels)):  # Evitar duplicados\n",
    "\n",
    "                weight = sync_matrix[k][i, j]# mismo orden en columnas y filas que lista 'channels'\n",
    "\n",
    "                if abs(weight) > cut_off:  # Filtrar conexiones debiles\n",
    "                    # Nos aseguramos de seleccionar correctamente los canales en orden\n",
    "                    x1, y1 = electrodes[channels[i]]\n",
    "                    x2, y2 = electrodes[channels[j]]\n",
    "\n",
    "                    normalized_weight = (weight - (-0.2)) / (0.2 - (-0.2))# Escala entre 0 y 1\n",
    "\n",
    "                    color = plt.cm.seismic(normalized_weight)# Necesita valores entre 0 y 1 para adjudicar colores correctamente\n",
    "\n",
    "                    linewidth = abs(weight)*15  # Grosor proporcional\n",
    "                    # Graficamos\n",
    "                    ax.plot([x1, x2], [y1, y2], color=color, linewidth=linewidth, alpha=0.8)\n",
    "\n",
    "        # Fondo gris\n",
    "        ax.set_facecolor('lightgray')\n",
    "\n",
    "        ax.set_title(subtitle[k])\n",
    "        ax.scatter(x_coords, y_coords, c=\"gray\", s=200, edgecolors=\"black\", zorder=3)\n",
    "        ax.set_xticks([])  # Eliminar las marcas en el eje X\n",
    "        ax.set_yticks([])  # Eliminar las marcas en el eje Y\n",
    "        ax.set_xlim([-1.2, 1.2])\n",
    "        ax.set_ylim([-1.0, 1.0])\n",
    "\n",
    "        # Agregar etiquetas con alineacion condicional\n",
    "        for label, (x, y) in electrodes.items():\n",
    "            ha = \"left\" if x > 0 else \"right\" if x < 0 else \"center\"\n",
    "            ax.text(x, y+0.05, label, fontsize=12, ha=ha, va='bottom')\n",
    "\n",
    "        # Dibujar las circunferencias en el gráfico\n",
    "        for r in circunferencias:\n",
    "            circle = plt.Circle((0,0), r, color='gray', fill=False, linestyle='--', linewidth=0.5)\n",
    "            ax.add_artist(circle)\n",
    "\n",
    "    # Ocultamos los ejes de la cuarta y quinta figura\n",
    "    axes[-1].axis('off')\n",
    "\n",
    "    # Crear la barra de colores en la cuarta columna \n",
    "    # Necesitamos crear una imagen ficticia para la colorbar. Usamos una dispersión\n",
    "    sc = axes[0].scatter([], [], c=[], cmap=\"bwr\", vmin=vmin, vmax=vmax)  # Definimos un scatter vacío con la colormap y límites\n",
    "\n",
    "    cbar = fig.colorbar(sc, ax=axes, orientation='vertical', fraction=0.02, pad=0.01)\n",
    "    cbar.set_label('Increase (red) to Decrease (blue)', fontsize=12, rotation=270, labelpad=20)\n",
    "\n",
    "    cbar.set_ticks([])\n",
    "\n",
    "    # Ajustamos diseño manualmente\n",
    "    fig.subplots_adjust(left=0.05, right=0.9, wspace=0.15)\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos la entropia de aproximacion por instante\n",
    "apEn_pre, apEn_post = Utils.group_by(df_tgt_apEn[df_tgt_apEn['comp']=='all'], col=\"instante\", val=[\"PRE\",\"POST\"])\n",
    "\n",
    "# Seleccionamos la entropia de aproximacion por instante y de todo el estimulo (all).\n",
    "apEn_pre_ctrl, apEn_pre_plcb, apEn_pre_exp = Utils.group_by(apEn_pre, col=\"grupo\", val=grupos)\n",
    "apEn_post_ctrl, apEn_post_plcb, apEn_post_exp = Utils.group_by(apEn_post, col=\"grupo\", val=grupos)\n",
    "\n",
    "# Calculamos la diferencia de apEn entre POST-PRE\n",
    "diff_ctrl = Entropy.compute_diff(apEn_post_ctrl, apEn_pre_ctrl)\n",
    "\n",
    "diff_plcb = Entropy.compute_diff(apEn_post_plcb, apEn_pre_plcb)\n",
    "\n",
    "diff_exp = Entropy.compute_diff(apEn_post_exp, apEn_pre_exp)\n",
    "\n",
    "# Calculamos la diferencia mediana por electrodo en cada grupo\n",
    "\n",
    "# Approximation entropy: [ctrl_array, plcb_array, exp_array]\n",
    "apEn_arrays = [diff_ctrl.median(), diff_plcb.median(), diff_exp.median()]\n",
    "\n",
    "# Coherence matrix: [ctrl_matrix, plcb_matrix, exp_matrix]\n",
    "coherence_matrices = diff_tgt_coherence[\"all\"]\n",
    "\n",
    "\n",
    "\n",
    "plot_graph(coherence_matrices, channels, electrodes, title=\"Target-All\", subtitle=[\"CTRL\",\"PLCB\",\"EXP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos la entropia de aproximacion por instante\n",
    "apEn_pre, apEn_post = Utils.group_by(df_delta, col=\"instante\", val=[\"PRE\",\"POST\"])\n",
    "\n",
    "# Seleccionamos la entropia de aproximacion por instante y de todo el estimulo (all).\n",
    "apEn_pre_ctrl, apEn_pre_plcb, apEn_pre_exp = Utils.group_by(apEn_pre[apEn_pre['comp']=='all'], col=\"grupo\", val=[\"CONTROL\", \"PLCB\", \"EXP\"])\n",
    "apEn_post_ctrl, apEn_post_plcb, apEn_post_exp = Utils.group_by(apEn_post[apEn_post['comp']=='all'], col=\"grupo\", val=[\"CONTROL\", \"PLCB\", \"EXP\"])\n",
    "\n",
    "# Calculamos la diferencia de apEn entre POST-PRE\n",
    "diff_ctrl = Entropy.compute_diff(apEn_post_ctrl[apEn_post_ctrl['comp']=='all'], \n",
    "                                 apEn_pre_ctrl[apEn_pre_ctrl['comp']=='all'])\n",
    "\n",
    "diff_plcb = Entropy.compute_diff(apEn_post_plcb[apEn_post_plcb['comp']=='all'], \n",
    "                                 apEn_pre_plcb[apEn_pre_plcb['comp']=='all'])\n",
    "\n",
    "diff_exp = Entropy.compute_diff(apEn_post_exp[apEn_post_exp['comp']=='all'], \n",
    "                                apEn_pre_exp[apEn_pre_exp['comp']=='all'])\n",
    "\n",
    "# Calculamos la diferencia mediana por electrodo en cada grupo\n",
    "\n",
    "# Approximation entropy: [ctrl_array, plcb_array, exp_array]\n",
    "apEn_arrays = [diff_ctrl.median(), diff_plcb.median(), diff_exp.median()]\n",
    "\n",
    "# Coherence matrix: [ctrl_matrix, plcb_matrix, exp_matrix]\n",
    "coherence_matrices = diff_tgt_coherence[\"delta\"]\n",
    "\n",
    "plot_graph(coherence_matrices, channels, electrodes, title=\"Target-Delta\", subtitle=[\"CTRL\",\"PLCB\",\"EXP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos la entropia de aproximacion por instante\n",
    "apEn_pre, apEn_post = Utils.group_by(df_theta, col=\"instante\", val=[\"PRE\",\"POST\"])\n",
    "\n",
    "# Seleccionamos la entropia de aproximacion por instante y de todo el estimulo (all).\n",
    "apEn_pre_ctrl, apEn_pre_plcb, apEn_pre_exp = Utils.group_by(apEn_pre[apEn_pre['comp']=='all'], col=\"grupo\", val=[\"CONTROL\", \"PLCB\", \"EXP\"])\n",
    "apEn_post_ctrl, apEn_post_plcb, apEn_post_exp = Utils.group_by(apEn_post[apEn_post['comp']=='all'], col=\"grupo\", val=[\"CONTROL\", \"PLCB\", \"EXP\"])\n",
    "\n",
    "# Calculamos la diferencia de apEn entre POST-PRE\n",
    "diff_ctrl = Entropy.compute_diff(apEn_post_ctrl[apEn_post_ctrl['comp']=='all'], \n",
    "                                 apEn_pre_ctrl[apEn_pre_ctrl['comp']=='all'])\n",
    "\n",
    "diff_plcb = Entropy.compute_diff(apEn_post_plcb[apEn_post_plcb['comp']=='all'], \n",
    "                                 apEn_pre_plcb[apEn_pre_plcb['comp']=='all'])\n",
    "\n",
    "diff_exp = Entropy.compute_diff(apEn_post_exp[apEn_post_exp['comp']=='all'], \n",
    "                                apEn_pre_exp[apEn_pre_exp['comp']=='all'])\n",
    "\n",
    "# Approximation entropy: [ctrl_array, plcb_array, exp_array]\n",
    "apEn_arrays = [diff_ctrl.median(), diff_plcb.median(), diff_exp.median()]\n",
    "\n",
    "# Coherence matrix: [ctrl_matrix, plcb_matrix, exp_matrix]\n",
    "coherence_matrices = diff_tgt_coherence[\"theta\"]\n",
    "\n",
    "plot_graph(coherence_matrices, channels, electrodes, title=\"Target-Theta\", subtitle=[\"CTRL\",\"PLCB\",\"EXP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos la entropia de aproximacion por instante\n",
    "apEn_pre, apEn_post = Utils.group_by(df_alpha, col=\"instante\", val=[\"PRE\",\"POST\"])\n",
    "\n",
    "# Seleccionamos la entropia de aproximacion por instante y de todo el estimulo (all).\n",
    "apEn_pre_ctrl, apEn_pre_plcb, apEn_pre_exp = Utils.group_by(apEn_pre[apEn_pre['comp']=='all'], col=\"grupo\", val=[\"CONTROL\", \"PLCB\", \"EXP\"])\n",
    "apEn_post_ctrl, apEn_post_plcb, apEn_post_exp = Utils.group_by(apEn_post[apEn_post['comp']=='all'], col=\"grupo\", val=[\"CONTROL\", \"PLCB\", \"EXP\"])\n",
    "\n",
    "# Calculamos la diferencia de apEn entre POST-PRE\n",
    "diff_ctrl = Entropy.compute_diff(apEn_post_ctrl[apEn_post_ctrl['comp']=='all'], \n",
    "                                 apEn_pre_ctrl[apEn_pre_ctrl['comp']=='all'])\n",
    "\n",
    "diff_plcb = Entropy.compute_diff(apEn_post_plcb[apEn_post_plcb['comp']=='all'], \n",
    "                                 apEn_pre_plcb[apEn_pre_plcb['comp']=='all'])\n",
    "\n",
    "diff_exp = Entropy.compute_diff(apEn_post_exp[apEn_post_exp['comp']=='all'], \n",
    "                                apEn_pre_exp[apEn_pre_exp['comp']=='all'])\n",
    "\n",
    "# Approximation entropy: [ctrl_array, plcb_array, exp_array]\n",
    "apEn_arrays = [diff_ctrl.median(), diff_plcb.median(), diff_exp.median()]\n",
    "\n",
    "# Coherence matrix: [ctrl_matrix, plcb_matrix, exp_matrix]\n",
    "coherence_matrices = diff_tgt_coherence[\"alpha\"]\n",
    "\n",
    "plot_graph(coherence_matrices, channels, electrodes, title=\"Target-Alpha\", subtitle=[\"CTRL\",\"PLCB\",\"EXP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos la entropia de aproximacion por instante\n",
    "apEn_pre, apEn_post = Utils.group_by(df_beta, col=\"instante\", val=[\"PRE\",\"POST\"])\n",
    "\n",
    "# Seleccionamos la entropia de aproximacion por instante y de todo el estimulo (all).\n",
    "apEn_pre_ctrl, apEn_pre_plcb, apEn_pre_exp = Utils.group_by(apEn_pre[apEn_pre['comp']=='all'], col=\"grupo\", val=[\"CONTROL\", \"PLCB\", \"EXP\"])\n",
    "apEn_post_ctrl, apEn_post_plcb, apEn_post_exp = Utils.group_by(apEn_post[apEn_post['comp']=='all'], col=\"grupo\", val=[\"CONTROL\", \"PLCB\", \"EXP\"])\n",
    "\n",
    "# Calculamos la diferencia de apEn entre POST-PRE\n",
    "diff_ctrl = Entropy.compute_diff(apEn_post_ctrl[apEn_post_ctrl['comp']=='all'], \n",
    "                                 apEn_pre_ctrl[apEn_pre_ctrl['comp']=='all'])\n",
    "\n",
    "diff_plcb = Entropy.compute_diff(apEn_post_plcb[apEn_post_plcb['comp']=='all'], \n",
    "                                 apEn_pre_plcb[apEn_pre_plcb['comp']=='all'])\n",
    "\n",
    "diff_exp = Entropy.compute_diff(apEn_post_exp[apEn_post_exp['comp']=='all'], \n",
    "                                apEn_pre_exp[apEn_pre_exp['comp']=='all'])\n",
    "\n",
    "# Approximation entropy: [ctrl_array, plcb_array, exp_array]\n",
    "apEn_arrays = [diff_ctrl.median(), diff_plcb.median(), diff_exp.median()]\n",
    "\n",
    "# Coherence matrix: [ctrl_matrix, plcb_matrix, exp_matrix]\n",
    "coherence_matrices = diff_tgt_coherence[\"beta\"]\n",
    "\n",
    "plot_graph(coherence_matrices, channels, electrodes, title=\"Target-Beta\", subtitle=[\"CTRL\",\"PLCB\",\"EXP\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time response\n",
    "\n",
    "$$Event\\ Related\\ Potentials\\ (ERP)\\ Components$$\n",
    "\n",
    "$$\n",
    "\\begin{array}{|c|c|c|}\n",
    "\\hline\n",
    "\\textbf{Componentes} & \\textbf{$t_{o}$ [ms]} & \\textbf{$t_{f}$ [ms]} \\\\\n",
    "\\hline\n",
    "\\text{P1} & 80 & 130 \\\\ \\hline\n",
    "\\text{N1} & 130 & 200 \\\\ \\hline\n",
    "\\text{P2} & 200 & 300 \\\\ \\hline\n",
    "\\text{N2} & 300 & 360 \\\\ \\hline\n",
    "\\text{P3} & 360 & 600 \\\\ \\hline\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Se han llevado a cabo dos tipos de contrastes:\n",
    "\n",
    "1) Para cada instante, se han analizado los grupos como distribuciones independientes.\n",
    "\n",
    "    - Instante PRE:\n",
    "        - CTRL vs PLCB\n",
    "        - CTRL vs EXP\n",
    "        - EXP vs PLCB\n",
    "\n",
    "    - Instante POST:\n",
    "        - CTRL vs PLCB\n",
    "        - CTRL vs EXP\n",
    "        - EXP vs PLCB\n",
    "\n",
    "    - Conclusión: \n",
    "\n",
    "        - En el instante PRE, los grupos presentan diferencias significativas entre sí, lo cual resulta inconsistente, ya que se asume que parten de condiciones similares. \n",
    "        - A la luz de estos resultados y los obtenidos en el instante POST, aunque también muestren diferencias significativas, no parecen ser del todo fiables. \n",
    "        - Descarto este tipo de comparación y solo tengo en cuenta los contrastes de instantes dentro de cada grupo.\n",
    "\n",
    "2) Para cada grupo, se ha analizado el cambio entre los instantes PRE y POST como distribuciones pareadas.\n",
    "\n",
    "    - Grupo CTRL:\n",
    "        - PRE vs POST\n",
    "    - Grupo PLCB:\n",
    "        - PRE vs POST\n",
    "    - Grupo EXP:\n",
    "        - PRE vs POST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths with files (.csv)\n",
    "path_tgt = \"E:/TFM/CLUSTERING_ALL_ICA_by_segments/ODDBALL/times_tgt.csv\"\n",
    "path_std = \"E:/TFM/CLUSTERING_ALL_ICA_by_segments/ODDBALL/times_std.csv\"\n",
    "\n",
    "# Load DataFrame for every type of stimulus\n",
    "df_t_tgt, df_t_std = pd.read_csv(path_tgt, header=0, delimiter=';'), pd.read_csv(path_std, header=0, delimiter=';')\n",
    "\n",
    "# Common information about both DataFrames, where: df_std.columns == df_tgt.columns\n",
    "channels = df_t_tgt.columns[6:].to_list()\n",
    "info = df_t_tgt.columns[:6].to_list()\n",
    "components = df_t_tgt[\"comp\"].unique()\n",
    "\n",
    "# Seleccionamos instantes de TARGET DataFrames\n",
    "tgt_instante = dict(zip([\"PRE\",\"POST\"], Utils.group_by(df_t_tgt, col=\"instante\", val=[\"PRE\", \"POST\"])))\n",
    "# Seleccionamos instantes de STANDARD DataFrames\n",
    "std_instante = dict(zip([\"PRE\",\"POST\"], Utils.group_by(df_t_std, col=\"instante\", val=[\"PRE\", \"POST\"])))\n",
    "\n",
    "# Seleccionamos instante PRE de TARGET DataFrames\n",
    "tgt_pre_grupo = dict(zip([\"CONTROL\",\"PLCB\",\"EXP\"], Utils.group_by(tgt_instante[\"PRE\"], col=\"grupo\", val=[\"CONTROL\", \"PLCB\", \"EXP\"])))\n",
    "# Seleccionamos instante PRE de STANDARD DataFrames\n",
    "std_pre_grupo = dict(zip([\"CONTROL\",\"PLCB\",\"EXP\"], Utils.group_by(std_instante[\"PRE\"], col=\"grupo\", val=[\"CONTROL\", \"PLCB\", \"EXP\"])))\n",
    "\n",
    "# Seleccionamos instante POST de TARGET DataFrames\n",
    "tgt_post_grupo = dict(zip([\"CONTROL\",\"PLCB\",\"EXP\"], Utils.group_by(tgt_instante[\"POST\"], col=\"grupo\", val=[\"CONTROL\", \"PLCB\", \"EXP\"])))\n",
    "# Seleccionamos instante POST de STANDARD DataFrames\n",
    "std_post_grupo = dict(zip([\"CONTROL\",\"PLCB\",\"EXP\"], Utils.group_by(std_instante[\"POST\"], col=\"grupo\", val=[\"CONTROL\", \"PLCB\", \"EXP\"])))\n",
    "\n",
    "# Seleccionamos sujetos comunes entre instantes\n",
    "tgt_pre_grupo[\"CONTROL\"], tgt_post_grupo[\"CONTROL\"] = Utils.select_common_ids(tgt_pre_grupo[\"CONTROL\"], tgt_post_grupo[\"CONTROL\"])\n",
    "tgt_pre_grupo[\"PLCB\"], tgt_post_grupo[\"PLCB\"] = Utils.select_common_ids(tgt_pre_grupo[\"PLCB\"], tgt_post_grupo[\"PLCB\"])\n",
    "tgt_pre_grupo[\"EXP\"], tgt_post_grupo[\"EXP\"] = Utils.select_common_ids(tgt_pre_grupo[\"EXP\"], tgt_post_grupo[\"EXP\"])\n",
    "\n",
    "std_pre_grupo[\"CONTROL\"], std_post_grupo[\"CONTROL\"] = Utils.select_common_ids(std_pre_grupo[\"CONTROL\"], std_post_grupo[\"CONTROL\"])\n",
    "std_pre_grupo[\"PLCB\"], std_post_grupo[\"PLCB\"] = Utils.select_common_ids(std_pre_grupo[\"PLCB\"], std_post_grupo[\"PLCB\"])\n",
    "std_pre_grupo[\"EXP\"], std_post_grupo[\"EXP\"] = Utils.select_common_ids(std_pre_grupo[\"EXP\"], std_post_grupo[\"EXP\"])\n",
    "\n",
    "print(\"Header with info:\",info)\n",
    "print(\"Channels:\",channels)\n",
    "print(\"Components:\",components)\n",
    "\n",
    "best_channels = list(set(channels) ^ set(['P8','T8', 'P4', 'O1', 'Oz', 'O2', 'Pz', 'P3', 'T7', 'P7']))  # Operador XOR (^) en conjuntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_diff(tgt_post, tgt_pre, groups, channels, c):\n",
    "\n",
    "    data = []\n",
    "    for g in groups:\n",
    "        df1, df0 = tgt_post[g], tgt_pre[g]\n",
    "        diff = []\n",
    "        for (n,id), df0_id in df0.groupby([\"n_test\",\"id\"]):\n",
    "\n",
    "            df1_id = Utils.group_by(df1[df1['n_test']==n], col=\"id\", val=[id])[0]\n",
    "\n",
    "            post = df1_id[df1_id['comp']==c].loc[:,channels].values\n",
    "            pre = df0_id[df0_id['comp']==c].loc[:,channels].values\n",
    "\n",
    "            d = post-pre\n",
    "            diff.append(d)\n",
    "        data.append(np.vstack(diff))\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for c in components:\n",
    "    ctrl, plcb, exp = compute_diff(tgt_post_grupo, tgt_pre_grupo, [\"CONTROL\", \"PLCB\", \"EXP\"], channels, c)\n",
    "        \n",
    "\n",
    "    # Circunferencias concentricas \n",
    "    circunferencias = np.arange(0, 1.5, 0.2)\n",
    "\n",
    "    # Extraemos las coordenadas\n",
    "    x = [coord[0] for coord in electrodes.values()]\n",
    "    y = [coord[1] for coord in electrodes.values()]\n",
    "\n",
    "    data = [np.median(ctrl, axis=0), np.median(plcb, axis = 0), np.median(exp, axis=0)]\n",
    "    lim = np.max([np.abs(np.min(data)), np.abs(np.max(data))])\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    title = c\n",
    "    subtitles = [\"CTRL\",\"PLCB\",\"EXP\"]\n",
    "    # Crear una figura con 1 fila y 3 columnas\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(18, 6), gridspec_kw={\"width_ratios\": [1, 1, 1, 0.05]})\n",
    "    plt.suptitle('['+title+']'+r' Time ($\\Delta$ POST-PRE)', fontsize=16)\n",
    "\n",
    "    for i, ax in enumerate(axes[:-1]):\n",
    "        for j in range(len(channels)):\n",
    "            x, y = electrodes[channels[j]]\n",
    "            sc = ax.scatter(x, y, c=data[i][j], cmap=\"coolwarm\", s=200, vmin=-lim, vmax = lim)\n",
    "        ax.set_facecolor('lightgray')\n",
    "        ax.set_title(subtitles[i])\n",
    "        ax.set_xticks([])  # Eliminar las marcas en el eje X\n",
    "        ax.set_yticks([])  # Eliminar las marcas en el eje Y\n",
    "        ax.set_xlim([-1.2, 1.2])\n",
    "        ax.set_ylim([-1.0, 1.0])\n",
    "        ax.grid(True)\n",
    "\n",
    "        # Etiquetas de los electrodos en cada grafico\n",
    "        for label, (i, j) in electrodes.items():\n",
    "            ha = \"left\" if i > 0 else \"right\" if i < 0 else \"center\"\n",
    "            ax.text(i, j, label, fontsize=14, ha=ha)\n",
    "\n",
    "        # Dibujar las circunferencias en el gráfico\n",
    "        for r in circunferencias:\n",
    "            circle = plt.Circle((0,0), r, color='gray', fill=False, linestyle='--', linewidth=0.5)\n",
    "            ax.add_artist(circle)\n",
    "\n",
    "    # Ocultamos los ejes de la cuarta figura\n",
    "    axes[-1].axis('off')\n",
    "\n",
    "    # Crear la barra de colores en la cuarta columna\n",
    "    fig.colorbar(sc, ax=axes, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "\n",
    "    # Ajustamos diseño manualmente\n",
    "    fig.subplots_adjust(left=0.05, right=0.9, wspace=0.15)\n",
    "\n",
    "    # Mostrar el grafico\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_rel\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import numpy as np\n",
    "\n",
    "# Suponiendo que ya tienes tus datos y utilidades listos\n",
    "eeg_regions = {\n",
    "    \"Frontal\": [\"Fp1\", \"Fp2\", \"F3\", \"Fz\", \"F4\", \"F7\", \"F8\"],\n",
    "    \"Central\": [\"C3\", \"Cz\", \"C4\"],\n",
    "    \"Parietal\": [\"P3\", \"Pz\", \"P4\"],\n",
    "    \"Occipital\": [\"O1\", \"Oz\", \"O2\"],\n",
    "    \"Temporal\": [\"T7\", \"T8\"],\n",
    "    \"Parieto-temporal\": [\"P7\", \"P8\"],\n",
    "    \"Parieto-occipital\": [\"P3\", \"P4\"],\n",
    "    \"Linea-media\": [\"Fz\", \"Cz\", \"Pz\"]  \n",
    "}\n",
    "\n",
    "# Lista vacía para almacenar los resultados\n",
    "results = []\n",
    "\n",
    "# Función para calcular la d de Cohen para muestras pareadas\n",
    "def cohen_d_paired(post, pre):\n",
    "    # Calcular las diferencias entre las mediciones pre y post\n",
    "    differences = post - pre\n",
    "    # Calcular la desviación estándar de las diferencias\n",
    "    sd_diff = np.std(differences, ddof=1)\n",
    "    # Calcular la media de las diferencias\n",
    "    mean_diff = np.mean(differences)\n",
    "    # Calcular d de Cohen\n",
    "    d = mean_diff / sd_diff\n",
    "    return d\n",
    "\n",
    "# Iterar sobre las regiones, componentes y grupos\n",
    "for k, v in eeg_regions.items():\n",
    "    for c in components:  # Asumiendo que 'components' está definido\n",
    "        for g in [\"CONTROL\", \"PLCB\", \"EXP\"]:\n",
    "            \n",
    "            # Filtrar datos para el grupo y componente\n",
    "            ctrl_pre = Utils.group_by(tgt_pre_grupo[g], col=\"comp\", val=[c])[0]\n",
    "            ctrl_post = Utils.group_by(tgt_post_grupo[g], col=\"comp\", val=[c])[0]\n",
    "\n",
    "            # Calcular los promedios de las regiones por sujeto\n",
    "            lista_pre = ctrl_pre.loc[:, v].mean(axis=1)\n",
    "            lista_post = ctrl_post.loc[:, v].mean(axis=1)\n",
    "\n",
    "            # Aplicar t-test pareado\n",
    "            t_stat, p_value = ttest_rel(lista_post,lista_pre)\n",
    "\n",
    "            # Calcular la d de Cohen\n",
    "            cohen_d = cohen_d_paired(lista_post, lista_pre)\n",
    "\n",
    "            # Determinar si PRE > POST o PRE < POST\n",
    "            if t_stat > 0:\n",
    "                pre_vs_post = \"PRE < POST\"\n",
    "            elif t_stat < 0:\n",
    "                pre_vs_post = \"PRE > POST\"\n",
    "            else:\n",
    "                pre_vs_post = \"PRE = POST\"\n",
    "\n",
    "            # Guardar los resultados si p-value es significativo\n",
    "            if p_value < 0.05:\n",
    "                result = {\n",
    "                    'Region': k,\n",
    "                    'Component': c,\n",
    "                    'Group': g,\n",
    "                    't-statistic': t_stat,\n",
    "                    'p-value': p_value,\n",
    "                    'Cohen-d': cohen_d,\n",
    "                    'PRE vs POST': pre_vs_post\n",
    "                }\n",
    "\n",
    "                # Agregar el resultado al listado\n",
    "                results.append(result)\n",
    "\n",
    "# Convertir el listado de resultados en un DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Ajustar los p-valores usando el método de Benjamini-Hochberg (FDR)\n",
    "results_df['p-value_adjusted'] = multipletests(results_df['p-value'], method='fdr_bh')[1]\n",
    "\n",
    "# Mostrar el DataFrame con los resultados ajustados\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl_pre = tgt_pre_grupo[\"CONTROL\"]\n",
    "ctrl_post = tgt_post_grupo[\"CONTROL\"]\n",
    "\n",
    "data_pre = [ctrl_pre[ctrl_pre['comp']==c].loc[:, ['Fz','Pz','Cz']].values.flatten() for c in components]\n",
    "data_post = [ctrl_post[ctrl_post['comp']==c].loc[:, ['Fz','Pz','Cz']].values.flatten() for c in components]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Crear la figura con subgráficos\n",
    "fig, axes = plt.subplots(1, len(components), figsize=(15, 5))\n",
    "\n",
    "# Graficar cada par Pre/Post en un subplot\n",
    "for i, c in enumerate(components):\n",
    "    df = pd.DataFrame({\n",
    "        \"Valores\": np.concatenate([data_pre[i], data_post[i]]),\n",
    "        \"Condición\": [\"Pre\"] * len(data_pre[i]) + [\"Post\"] * len(data_post[i])\n",
    "    })\n",
    "    \n",
    "    sns.boxplot(x=\"Condición\", y=\"Valores\", data=df, ax=axes[i])\n",
    "    axes[i].set_title(f\"Comparación para {c}\")\n",
    "    axes[i].set_xlabel(\"Condición\")\n",
    "    axes[i].set_ylabel(\"Valores\")\n",
    "\n",
    "# Ajustar el diseño y mostrar\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl_pre = tgt_pre_grupo[\"PLCB\"]\n",
    "ctrl_post = tgt_post_grupo[\"PLCB\"]\n",
    "\n",
    "data_pre = [ctrl_pre[ctrl_pre['comp']==c].loc[:, channels].values.flatten() for c in components]\n",
    "data_post = [ctrl_post[ctrl_post['comp']==c].loc[:, channels].values.flatten() for c in components]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Crear la figura con subgráficos\n",
    "fig, axes = plt.subplots(1, len(components), figsize=(15, 5))\n",
    "\n",
    "# Graficar cada par Pre/Post en un subplot\n",
    "for i, c in enumerate(components):\n",
    "    df = pd.DataFrame({\n",
    "        \"Valores\": np.concatenate([data_pre[i], data_post[i]]),\n",
    "        \"Condición\": [\"Pre\"] * len(data_pre[i]) + [\"Post\"] * len(data_post[i])\n",
    "    })\n",
    "    \n",
    "    sns.boxplot(x=\"Condición\", y=\"Valores\", data=df, ax=axes[i])\n",
    "    axes[i].set_title(f\"Comparación para {c}\")\n",
    "    axes[i].set_xlabel(\"Condición\")\n",
    "    axes[i].set_ylabel(\"Valores\")\n",
    "\n",
    "# Ajustar el diseño y mostrar\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl_pre = tgt_pre_grupo[\"EXP\"]\n",
    "ctrl_post = tgt_post_grupo[\"EXP\"]\n",
    "\n",
    "data_pre = [ctrl_pre[ctrl_pre['comp']==c].loc[:, ['Fz','Pz','Cz']].values.flatten() for c in components]\n",
    "data_post = [ctrl_post[ctrl_post['comp']==c].loc[:, ['Fz','Pz','Cz']].values.flatten() for c in components]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Crear la figura con subgráficos\n",
    "fig, axes = plt.subplots(1, len(components), figsize=(15, 5))\n",
    "\n",
    "# Graficar cada par Pre/Post en un subplot\n",
    "for i, c in enumerate(components):\n",
    "    df = pd.DataFrame({\n",
    "        \"Valores\": np.concatenate([data_pre[i], data_post[i]]),\n",
    "        \"Condición\": [\"Pre\"] * len(data_pre[i]) + [\"Post\"] * len(data_post[i])\n",
    "    })\n",
    "    \n",
    "    sns.boxplot(x=\"Condición\", y=\"Valores\", data=df, ax=axes[i])\n",
    "    axes[i].set_title(f\"Comparación para {c}\")\n",
    "    axes[i].set_xlabel(\"Condición\")\n",
    "    axes[i].set_ylabel(\"Valores\")\n",
    "\n",
    "# Ajustar el diseño y mostrar\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs_t_tgt = {'PRE':[tgt_pre_grupo[\"CONTROL\"], tgt_pre_grupo[\"PLCB\"], tgt_pre_grupo[\"EXP\"]],\n",
    "#              'POST':[tgt_post_grupo[\"CONTROL\"], tgt_post_grupo[\"PLCB\"], tgt_post_grupo[\"EXP\"]]}\n",
    "\n",
    "# Time.plot_distributions(dfs_t_tgt, ['Pz','Cz'], components, title = \"[Target] Tiempos de respuesta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Lista que guardara los resultados\n",
    "# stats_results = []\n",
    "\n",
    "# # Por cada componente, then:\n",
    "# for comp in components:\n",
    "\n",
    "#     # Definimos diccionario con todos los datos pareados a comparar\n",
    "#     dict_time = {\n",
    "#         'CTRL': [tgt_pre_grupo[\"CONTROL\"][tgt_pre_grupo[\"CONTROL\"]['comp']==comp].loc[:,channels], tgt_post_grupo[\"CONTROL\"][tgt_post_grupo[\"CONTROL\"]['comp']==comp].loc[:,channels]],\n",
    "#         'PLCB': [tgt_pre_grupo[\"PLCB\"][tgt_pre_grupo[\"PLCB\"]['comp']==comp].loc[:,channels], tgt_post_grupo[\"PLCB\"][tgt_post_grupo[\"PLCB\"]['comp']==comp].loc[:,channels]],\n",
    "#         'EXP': [tgt_pre_grupo[\"EXP\"][tgt_pre_grupo[\"EXP\"]['comp']==comp].loc[:,channels], tgt_post_grupo[\"EXP\"][tgt_post_grupo[\"EXP\"]['comp']==comp].loc[:,channels]]}\n",
    "\n",
    "#     # Guardamos los resultados de los test pareados\n",
    "#     stats_results.append(Entropy.compute_paired_test(dict_time, comp, \"wilcoxon\"))\n",
    "\n",
    "# # Creamos un DataFrame con todos los estadisticos\n",
    "# results_df = pd.concat(stats_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df[(results_df['grupo']=='CTRL')&(results_df['cohens_d']>0)&(results_df['adj_p_value']<0.05)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df[(results_df['grupo']=='PLCB')&(results_df['cohens_d']>0)&(results_df['adj_p_value']<0.05)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df[(results_df['grupo']=='EXP')&(results_df['cohens_d']>0)&(results_df['adj_p_value']<0.05)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs_t_std = {'PRE':[df_t_std_pre_ctrl, df_t_std_pre_plcb, df_t_std_pre_exp],\n",
    "#              'POST':[df_t_std_post_ctrl, df_t_std_post_plcb, df_t_std_post_exp]}\n",
    "\n",
    "\n",
    "# Time.plot_distributions(dfs_t_std, cols, components, title = \"[Standard] Tiempos de respuesta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Seleccionamos los canales sobre los que computar los estadisticos\n",
    "# cols = np.array([channels.index(i) for i in best_channels], dtype=int)+6\n",
    "\n",
    "# # Lista que guardara los resultados\n",
    "# stats_results = []\n",
    "\n",
    "# # Por cada componente, then:\n",
    "# for comp in components:\n",
    "\n",
    "#     # Definimos diccionario con todos los datos pareados a comparar\n",
    "#     dict_time = {\n",
    "#         'CTRL': [df_t_std_pre_ctrl[df_t_std_pre_ctrl['comp']==comp].iloc[:,cols], df_t_std_post_ctrl[df_t_std_post_ctrl['comp']==comp].iloc[:,cols]],\n",
    "#         'PLCB': [df_t_std_pre_plcb[df_t_std_pre_plcb['comp']==comp].iloc[:,cols], df_t_std_post_plcb[df_t_std_post_plcb['comp']==comp].iloc[:,cols]],\n",
    "#         'EXP': [df_t_std_pre_exp[df_t_std_pre_exp['comp']==comp].iloc[:,cols], df_t_std_post_exp[df_t_std_post_exp['comp']==comp].iloc[:,cols]]}\n",
    "\n",
    "#     # Guardamos los resultados de los test pareados\n",
    "#     stats_results.append(Entropy.compute_paired_test(dict_time, comp, \"wilcoxon\"))\n",
    "\n",
    "# # Creamos un DataFrame con todos los estadisticos\n",
    "# results_df = pd.concat(stats_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df[(results_df['grupo']=='CTRL')&(results_df['cohens_d']>0.2)&(results_df['adj_p_value']<0.05)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df[(results_df['grupo']=='PLCB')&(results_df['cohens_d']>0.2)&(results_df['adj_p_value']<0.05)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df[(results_df['grupo']=='EXP')&(results_df['cohens_d']>0.2)&(results_df['adj_p_value']<0.05)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future tasks\n",
    "\n",
    "- Trabajar a nivel de bandas cerebrales.\n",
    "- Estudiar correlación cruzada, desfase y similitud entre señales. Consistencia en la periodicidad y diferencias en intensidad de deflexiones, entre otros.\n",
    "- Estudiar correlaciones entre componentes ERP, es decir, ¿aumento de una componente implica la disminución de otra dependiendo de la intervención?.\n",
    "- Estudiar la posibilidad del ajuste de un modelo por covariables y añadir la edad como covariable. \n",
    "- Analizar el tiempo de detección entre estímulos *target* y *standard*. Extrapolar conclusiones sobre el tiempo de respuesta dentro de cada grupo. \n",
    "\n",
    "Vamos a construir un modelo con la reserva cognitiva como variable respuesta y entropía, edad, media y varianza.\n",
    "\n",
    "Luego añadimos construimos modelo de regresión logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_groups = {\n",
    "    \"Frontal\": [\"Fp1\", \"Fp2\", \"F3\", \"Fz\", \"F4\", \"F7\", \"F8\"],\n",
    "    \"Central\": [\"C3\", \"Cz\", \"C4\"],\n",
    "    \"Parietal\": [\"P3\", \"Pz\", \"P4\"],\n",
    "    \"Occipital\": [\"O1\", \"Oz\", \"O2\"],\n",
    "    \"Temporal\": [\"T7\", \"T8\"],\n",
    "    \"Parietotemporal\": [\"P7\", \"P8\"],\n",
    "    \"Parieto-occipital\": [\"P3\", \"P4\"]\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
